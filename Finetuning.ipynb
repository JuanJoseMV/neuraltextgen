{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPteK5VPgXo5T+cBONs440p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e2995a2d4264584bd539fdce2024591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f08a76d943e40d7ba9ca248f8a0c97f",
              "IPY_MODEL_6ee42ecf2e7e413d9b06c9a2349007ec",
              "IPY_MODEL_60700a3e7b88407b8013f644ebc09b60"
            ],
            "layout": "IPY_MODEL_c5c5ede358cb43a1acf320c29458ad59"
          }
        },
        "1f08a76d943e40d7ba9ca248f8a0c97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec57be0f75ea4180ab0d3722aea333c2",
            "placeholder": "​",
            "style": "IPY_MODEL_9795382e0017498e80299558fc697be0",
            "value": "Downloading: 100%"
          }
        },
        "6ee42ecf2e7e413d9b06c9a2349007ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6c95e071874a9d912649d3e3fd04f0",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_592df71ef32c4b8da1075bb34fa84de2",
            "value": 433
          }
        },
        "60700a3e7b88407b8013f644ebc09b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb39b90e60f74d9daafd320718806d79",
            "placeholder": "​",
            "style": "IPY_MODEL_c013a45f17ec4cee9f0f47da84dd2441",
            "value": " 433/433 [00:00&lt;00:00, 9.03kB/s]"
          }
        },
        "c5c5ede358cb43a1acf320c29458ad59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec57be0f75ea4180ab0d3722aea333c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9795382e0017498e80299558fc697be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b6c95e071874a9d912649d3e3fd04f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592df71ef32c4b8da1075bb34fa84de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb39b90e60f74d9daafd320718806d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c013a45f17ec4cee9f0f47da84dd2441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d61b5d0409d49ebae8ce6a3b05d7788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8250756212e4cda997bb8eb8d1cf355",
              "IPY_MODEL_08522f389bce4dd99a82477a0096c488",
              "IPY_MODEL_3f2017a96a6a4940bd383aa2dae51ac9"
            ],
            "layout": "IPY_MODEL_1166a28bdb554cb19e3549b6c4d6c6cf"
          }
        },
        "c8250756212e4cda997bb8eb8d1cf355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34dee349bb764add93b48cfd8e4a7530",
            "placeholder": "​",
            "style": "IPY_MODEL_e28b64e42e2b4fe1993b6a48fa71057b",
            "value": "Downloading: 100%"
          }
        },
        "08522f389bce4dd99a82477a0096c488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84db804f7545448eb867e2d662f56a9c",
            "max": 442256008,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd92d25a59f3425abf65a1a205fd5bdd",
            "value": 442256008
          }
        },
        "3f2017a96a6a4940bd383aa2dae51ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d755beaf464f44ce9c54f281c187a200",
            "placeholder": "​",
            "style": "IPY_MODEL_871d27b1f6de4546a75c6464931db33b",
            "value": " 442M/442M [00:14&lt;00:00, 32.2MB/s]"
          }
        },
        "1166a28bdb554cb19e3549b6c4d6c6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dee349bb764add93b48cfd8e4a7530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28b64e42e2b4fe1993b6a48fa71057b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84db804f7545448eb867e2d662f56a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd92d25a59f3425abf65a1a205fd5bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d755beaf464f44ce9c54f281c187a200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871d27b1f6de4546a75c6464931db33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6284b64ff4ca4c4aa20f0e1ee32c2f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02f314b0181640f0909752b54402155f",
              "IPY_MODEL_77cfd732fc5b4474937181a6e1f7259f",
              "IPY_MODEL_a53be2098541401d90c450fe2106b486"
            ],
            "layout": "IPY_MODEL_2bdf6e5ab668489b839cd29233141514"
          }
        },
        "02f314b0181640f0909752b54402155f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ee919cd8e04b25bda596ac22fa6e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_08a242d04efa43ba9b783a8fabcfe40c",
            "value": "Downloading: 100%"
          }
        },
        "77cfd732fc5b4474937181a6e1f7259f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4cc103b69f74a76a57f97325545e8b1",
            "max": 59,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81875f4d54224a2a8118b3aad655bce5",
            "value": 59
          }
        },
        "a53be2098541401d90c450fe2106b486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d06329175d842fbad875bc6f58d29ea",
            "placeholder": "​",
            "style": "IPY_MODEL_56829d48aa974193b461fa93f39fd433",
            "value": " 59.0/59.0 [00:00&lt;00:00, 1.37kB/s]"
          }
        },
        "2bdf6e5ab668489b839cd29233141514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ee919cd8e04b25bda596ac22fa6e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08a242d04efa43ba9b783a8fabcfe40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4cc103b69f74a76a57f97325545e8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81875f4d54224a2a8118b3aad655bce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d06329175d842fbad875bc6f58d29ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56829d48aa974193b461fa93f39fd433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d242fa97fe4be6b5e05ee0733126c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9eb48f966f58441fad89d8541a29d713",
              "IPY_MODEL_dda70c58fd5d4a0e85fdac35f36367ce",
              "IPY_MODEL_af796fac21d4451cbd813e6c3b9a469a"
            ],
            "layout": "IPY_MODEL_d0c7383745b04b4aab5b51515d719b4e"
          }
        },
        "9eb48f966f58441fad89d8541a29d713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdcf640b3e254eb18ce572be73fe3781",
            "placeholder": "​",
            "style": "IPY_MODEL_88203639fad24edb944f7ecbd686ec00",
            "value": "Downloading: 100%"
          }
        },
        "dda70c58fd5d4a0e85fdac35f36367ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1a407f7c7745d7a6f9ad80ac7f2eb4",
            "max": 242585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dcf6c09a009494d9074dc14bb0ddc15",
            "value": 242585
          }
        },
        "af796fac21d4451cbd813e6c3b9a469a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_612ce61627734504a42d6b48b0058ccd",
            "placeholder": "​",
            "style": "IPY_MODEL_33f292e16a79404ebca121a4dd864f46",
            "value": " 243k/243k [00:00&lt;00:00, 1.40MB/s]"
          }
        },
        "d0c7383745b04b4aab5b51515d719b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcf640b3e254eb18ce572be73fe3781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88203639fad24edb944f7ecbd686ec00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec1a407f7c7745d7a6f9ad80ac7f2eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcf6c09a009494d9074dc14bb0ddc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "612ce61627734504a42d6b48b0058ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f292e16a79404ebca121a4dd864f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanJoseMV/neuraltextgen/blob/main/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zv2VNwnEG5q"
      },
      "source": [
        "# Installations\n",
        "## Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2xpKVddfn-p"
      },
      "source": [
        "%%capture\n",
        "!git clone --recursive https://github.com/JuanJoseMV/neuraltextgen.git\n",
        "!pip install -r /content/neuraltextgen/texygen/requirements.txt\n",
        "!pip install simpletransformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sCN5Q0J9Fv7"
      },
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import os\n",
        "os.chdir(\"/content/neuraltextgen/\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjEOS-ruEOEe"
      },
      "source": [
        "## Nvidia APEX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPrGAmeexF0C"
      },
      "source": [
        "%%capture\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkcX5aW8xHIw",
        "outputId": "14ff714d-ef2f-4e4f-d22e-0e099b01b947"
      },
      "source": [
        "%%writefile setup.sh\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzrKxdIUxMCX"
      },
      "source": [
        "%%capture\n",
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3Mw_u_-Xqcj"
      },
      "source": [
        "# Finetuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8CWeNHJFPZT"
      },
      "source": [
        "\n",
        "## Example 1 - Motivational quotes\n",
        "The first experiment is focused on showing the functionality of the fine-tuning of BertTextGenerator.\n",
        "To do this we will finetune an italian model on a small set of Italian motivational quotes, to try make him generate new ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8szsrK4FSN9"
      },
      "source": [
        "\n",
        "### Dataset creation\n",
        "We can start creating our dataset. To do this we will scrape some sites in order to gather a good amount of quotes.\n",
        "\n",
        "The first site we used is https://www.frasimania.it/frasi-motivazionali/, that contains 125 quotes as:\n",
        "\n",
        ">Prima ti ignorano, poi ti deridono, poi ti combattono. Poi vinci.\n",
        "(Mahatma Gandhi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnBOAIcQ-ev"
      },
      "source": [
        "import pandas as pd\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "\n",
        "url = \"https://www.frasimania.it/frasi-motivazionali/\"\n",
        "req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
        "webpage = urlopen(req).read()\n",
        "page_soup = soup(webpage, \"html.parser\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1I-o2RiuxUd"
      },
      "source": [
        "import re\n",
        "with open('/content/quotes.txt', 'w') as f:\n",
        "  containers = page_soup.findAll('p', attrs={'class':'singola'})\n",
        "  for container in containers:\n",
        "    quote = container.getText()\n",
        "    quote = quote.replace('\\n', ' ')\n",
        "    \n",
        "    quote, author = quote.split('(')\n",
        "    author = author.split(',')[0]\n",
        "    f.write(f'{quote.strip()} - ({author.strip()}\\n')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODWkuvkFItjk"
      },
      "source": [
        "\n",
        "The second site is \"https://aforisticamente.com/le-piu-belle-frasi-motivazionali/. Here there are 100 quotes as:\n",
        "> Abbiamo quaranta milioni di ragioni per fallire, ma non una sola scusa.\n",
        "(Rudyard Kipling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qabhb6YU5EW"
      },
      "source": [
        "import pandas as pd\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "\n",
        "url = \"https://aforisticamente.com/le-piu-belle-frasi-motivazionali/\"\n",
        "req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
        "webpage = urlopen(req).read()\n",
        "page_soup = soup(webpage, \"html.parser\")\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6oGYOeNvPDy"
      },
      "source": [
        "with open('/content/quotes.txt', 'a') as f:\n",
        "  containers = page_soup.findAll('p')\n",
        "  for container in containers[4:-10]:\n",
        "    quote = container.getText()\n",
        "    quote = quote.replace('\\n', ' ')\n",
        "\n",
        "    if len(quote) < 5:\n",
        "      pass\n",
        "    else:\n",
        "      quote, author = quote.split('(')\n",
        "      author = author.split(',')[0]\n",
        "      f.write(f'{quote.strip()} - ({author.strip()}\\n')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyJaUrAn6zev"
      },
      "source": [
        "The third site is https://www.oberlo.it/blog/frasi-motivazionali. Here there are 200 quotes. The quotes are structured a bit differently than in the previous examples\n",
        ">4. “Se le tue azioni ispirano gli altri a sognare di più, a imparare di più, a fare di più e a diventare di più, sei un leader.” — John Quincy Adams, 6° Presidente degli Stati Uniti (Clicca per twittare)\n",
        "\n",
        "There is a number prepended, a description of the author plus some other noise text that can ber removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu0fMHNPXvY5"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "\n",
        "url = \"https://www.oberlo.it/blog/frasi-motivazionali\"\n",
        "req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
        "webpage = urlopen(req).read()\n",
        "page_soup = soup(webpage, \"html.parser\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSOnKTMxX0Hz"
      },
      "source": [
        "containers = page_soup.findAll('p')\n",
        "text = [container.getText() for container in containers[:245]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMewQuHEZcb2"
      },
      "source": [
        "import re\n",
        "\n",
        "start = re.compile('^[\\d]+.')\n",
        "with open('/content/quotes.txt', 'a') as f:\n",
        "  for string in text:\n",
        "    matches = start.search(string) #only lines that start with a number\n",
        "    if matches:\n",
        "      try:\n",
        "        string = string[matches.end()+1:]\n",
        "        quote, author = string.split('—')\n",
        "        # quote = quote.replace('“','”')\n",
        "        quote = quote.replace('“','')\n",
        "        quote = quote.replace('”', '')\n",
        "        author = author.split(',')[0]\n",
        "        f.write(f'{quote.strip()} - ({author.strip()})\\n')\n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uj12LohKKoY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67TO3pwvbmcp"
      },
      "source": [
        "import pandas as pd\n",
        "from urllib.request import Request, urlopen\n",
        "from bs4 import BeautifulSoup as soup\n",
        "\n",
        "url = \"https://www.esserealtop.it/365-frasi-motivazionali-che-ti-cambieranno-la-vita/\"\n",
        "req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})\n",
        "webpage = urlopen(req).read()\n",
        "page_soup = soup(webpage, \"html.parser\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j62MjtEb2mh"
      },
      "source": [
        "containers = page_soup.findAll('p')\n",
        "text = [container.getText() for container in containers]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtV_YTlacB_c"
      },
      "source": [
        "with open('quotes.txt', 'a') as f:\n",
        "  for string in text:\n",
        "    if string.startswith('“'):\n",
        "  \n",
        "      string = string.replace('”', '“')\n",
        "      string = string.replace('”', '')\n",
        "      string = string.replace('“', '')\n",
        "      # string = string.replace('\\xa0', ' ')\n",
        "      \n",
        "      try:\n",
        "        quote, author = string.split('–')\n",
        "        # author = author.split(',')[0]\n",
        "        f.write(f'{quote.strip()} - ({author.strip()})\\n')\n",
        "        # f.write(splitted[0] + ' (' + author + ' )\\n')\n",
        "      except:\n",
        "        quote = string;\n",
        "        author = 'anonimo'\n",
        "        f.write(f'{quote.strip()} - {author.strip()}\\n')\n",
        "        \n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19MXPJWNMxNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb4ac65-9bee-4b90-e89b-136557a75120"
      },
      "source": [
        "for line in open('quotes.txt').readlines()[:10]:\n",
        "  print(line)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prima ti ignorano, poi ti deridono, poi ti combattono. Poi vinci. - (Mahatma Gandhi)\n",
            "\n",
            "Ho sempre tentato. Ho sempre fallito. Non discutere. Prova ancora. Fallisci ancora. Fallisci meglio. - (Samuel Beckett)\n",
            "\n",
            "Se vuoi qualcosa che non hai mai avuto, devi fare qualcosa che non hai mai fatto. - (Thomas Jefferson)\n",
            "\n",
            "Ci sono due regole nella vita: 1. Non mollare mai; 2. Non dimenticare mai la regola n° 1. - (Duke Ellington)\n",
            "\n",
            "La vita è per il 10% cosa ti accade e per il 90% come reagisci. - (Charles R. Swindoll)\n",
            "\n",
            "Non si è mai troppo vecchi per fissare un nuovo obiettivo o per sognare un nuovo sogno. - (C.S. Lewis)\n",
            "\n",
            "Non rinunciare a provare a fare ciò che vuoi veramente fare. Dove c’è amore e ispirazione, non credo che si possa sbagliare. - (Ella Fitzgerald)\n",
            "\n",
            "Due strade divergevano nel bosco, ed io… io scelsi quella meno battuta e questo fece la differenza. - (Robert Frost)\n",
            "\n",
            "Sono grato a tutte quelle persone che mi hanno detto di no. È grazie a loro se sono quel che sono. - (Albert Einstein)\n",
            "\n",
            "Il futuro appartiene a coloro che credono nella bellezza dei propri sogni. - (Eleanor Roosevelt)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG4tc52M8hg4"
      },
      "source": [
        "### Model\n",
        "Now that our set of quotes is ready we have practically done. It remains only to chose a pretrained BERT model and initliaze the BertTextGenerator. We will use this model https://huggingface.co/dbmdz/bert-base-italian-cased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ile541icdOFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ad9f45-5c93-4530-a626-34796c21592b"
      },
      "source": [
        "from NeuralTextGenerator import BertTextGenerator\n",
        "\n",
        "it_bert_model = BertTextGenerator(\"dbmdz/bert-base-italian-uncased\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-LL-G9-9g86"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr0aiPlC9ggn",
        "outputId": "87983290-a396-4d88-c684-f065ab3a699e"
      },
      "source": [
        "lines = open('/content/quotes.txt').readlines()\n",
        "it_bert_model.finetune(lines, epochs=4, batch_size=32,optimizer_parameters = dict(lr=5e-5))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 2.83\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:02:15 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEd8e7qbIeUd",
        "outputId": "7542b51a-7f28-408e-b74f-75879f3e4ab7"
      },
      "source": [
        "parameters = {'n_sentences': 3, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'parallel',\n",
        "              'max_iter':500,\n",
        "              'burnin':450,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carmen sevilla ( siviglia ), siviglia ( ana aquis ), renata berry ( lisbona ), sydney ( sydney )\n",
            "covent laurent favre ( oscar goethe ) jane fonda ( putin )\n",
            "! ) ( anonimo ) sto giocando con i delfini..!! ( anonimo ) ( rifugiato in siria )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQw5qxSM5vd",
        "outputId": "36672ab1-bfb7-442d-a992-c368330e2353"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              # 'std_len':5,\n",
        "              'generation_method':'parallel',\n",
        "              'max_iter':500,\n",
        "              # 'burnin':330,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/quotes_parallel_generation.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perche essere cosi ingenuo e no forse uno dei due non si ama lo stesso. ( henry franklin ) ( henry forde universita harvard )\n",
            "( ( ricorda cosa ti ho detto ) ) vincerai. ( anonimo ) ( arthur farioski ) ( henry wells ) ( anonimo )\n",
            "una vita poetica che ricorda le fiabe cosa vedere atena sheila ( film ) atena sheila ( piede )\n",
            "i juan la fortuna ( hernan camacho ), i juan la fama ( osho gosseto ), juan la fama ( paulo munari )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoo7v-NC15Gj",
        "outputId": "9bbe2b95-2aaf-4b6d-bc95-25dad47ef656"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              'burnin':330,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/quotes_attention_generation.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( john s. osborne brown ) ( san francisco ). ( l ’ autore e henry button ).\n",
            "(... )... (... ) ( michael schaferman )\n",
            "( ( huai ) ) ( ( huai ) ) ( huai ) ) ( ( huai ) ) ( ( hua ) ( ) )\n",
            "non potevamo separarci. potevamo... rimanere uniti. ( adam kaczynski )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZQ_pqVtVKVj",
        "outputId": "6c605a2f-83dd-474e-febd-d1cce15c01fe"
      },
      "source": [
        "parameters = {'n_sentences': 8, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              'burnin':330,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "se dirigi gli affari potresti non poter avere le raffinerie. ( j. schuller ) anche se si hanno solo le raffinerie non puoi disertare.\n",
            "se vuoi davvero fare una cosa, e meglio se la smetti di farla. ( thomas edison )\n",
            "quello che succede e che vinciamo e cadiamo fino al risultato finale ( anche se cadiamo come cagnetti )\n",
            "( se non vuoi essere con un cucchiaino in mano ), devi concentrarti su chi vuoi veramente essere. ( ra )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEe4EP-cVc__",
        "outputId": "cc39a9a5-c884-425d-b590-cdb114c21abc"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              'burnin':430,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a scrivere e a leggere le parole. ( anonimo )... da dove iniziare?\n",
            "[ j. k. ] \" so solo che sto lavorando per vincere. \" fidati, vincerai. ( henry j. d williamson ) ( anonimo )\n",
            "essere terrorizzato da freud fino al suo scopo. ma se devo lavorare tutta la notte per il mio scopo con esso devo lavorare tutta la notte per farlo.\n",
            "quando muori, la vita finisce. non ci resta che aspettare finche non muori, perche non sai cosa ti aspetta ( anonimo )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep0WnufjWKeJ",
        "outputId": "2c6e6088-9213-4989-b435-089a1045fcd4"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'sequential',\n",
        "              'max_iter':500,\n",
        "              'burnin':430,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "niente e meglio di fare quello che ti pare. e poi, ti sto dicendo che sei grande abbastanza.\n",
            "non hai nulla da fare, tutti i giorni, se non stai cercando di fare tutto cio che e necessario. ( norman bates )\n",
            "lo ho fatto perche sapevo che dovevo diventare uno, che lo avevo gia fatto e che avrei fallito quando ho capito che dovevo diventare uno.\n",
            "non e questo l ’ obiettivo a cui in realta sto mirando, sebbene sia quello che cerco sempre di raggiungere. ( joshua reynolds )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANXtM-eCfb7E",
        "outputId": "23277124-39e4-4e0c-aba0-e6213fee9dd3"
      },
      "source": [
        "parameters = {'n_sentences': 3, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'parallel',\n",
        "              'max_iter':500,\n",
        "              'burnin':450,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "faro del mio meglio per non essere trattato come un fallito. ma finche saro fallito, non lo faro. ( ripeto, ingra ) ( frank lloyd wright )\n",
            "provaci ( anche se non cadi ) sii un eroe. sii forte. sii coraggioso. sii un eroe.\n",
            "se poi ti rifiuti di fare cose buone, ti fermi per sempre. ( smetti di cercare di fare le cose che vuoi fare. )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNH4F3dheCdJ",
        "outputId": "7fa3e13e-e11e-4cd0-d6aa-8e7b67a8f1e8"
      },
      "source": [
        "parameters = {'n_sentences': 3, \n",
        "              'batch_size': 1, \n",
        "              'avg_len':25, \n",
        "              'std_len':5,\n",
        "              'generation_method':'parallel',\n",
        "              'max_iter':500\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mi piacerebbe trovare un nuovo modo per prepararmi a questa nuova sfida.\n",
            "no, vattene via, paul berry! ( paul berry che canta ) ( peter t. dieter ).\n",
            "moezsen sta provando a diventare ’ li ’ dentro. se stro qualcosa, ‘ allora si manifesta la sua trascendenza ’.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxdmsPBFaRwi",
        "outputId": "91e0ac5f-90c3-4b57-ae27-32ee0f952ed9"
      },
      "source": [
        "x = [       \"se dirigi gli affari potresti non poter avere le raffinerie. ( j. schuller )\\n\",\n",
        "            \"se vuoi davvero fare una cosa, e meglio se la smetti di farla. ( thomas edison )\\n\",\n",
        "            \"(... )... (... ) ( michael schaferman )\\n\",\n",
        "            \"( se non vuoi essere con un cucchiaino in mano ), devi concentrarti su chi vuoi veramente essere. ( ra )\\n\",\n",
        "            \"a scrivere e a leggere le parole. ( anonimo )... da dove iniziare?\\n\",\n",
        "            \"( ( huai ) ) ( ( huai ) ) ( huai ) ) ( ( huai ) ) ( ( hua ) ( ) )\\n\",\n",
        "            \"[ j. k. ] \\\" so solo che sto lavorando per vincere. \\\" fidati, vincerai. ( henry j. d williamson ) ( anonimo )\\n\",\n",
        "            \"quando muori, la vita finisce. non ci resta che aspettare finche non muori, perche non sai cosa ti aspetta ( anonimo )\\n\",\n",
        "            \"faro del mio meglio per non essere trattato come un fallito. ma finche saro fallito, non lo faro. ( ripeto, ingra ) ( frank lloyd wright )\\n\",\n",
        "            \"provaci ( anche se non cadi ) sii un eroe. sii forte. sii coraggioso. sii un eroe.\\n\",\n",
        "            \"se poi ti rifiuti di fare cose buone, ti fermi per sempre. ( smetti di cercare di fare le cose che vuoi fare. )\\n\",\n",
        "            \"mi piacerebbe trovare un nuovo modo per prepararmi a questa nuova sfida.\\n\",\n",
        "            \"no, vattene via, paul berry! ( paul berry che canta ) ( peter t. dieter ).\\n\",\n",
        "            \"moezsen sta provando a diventare ’ li ’ dentro. se stro qualcosa, ‘ allora si manifesta la sua trascendenza ’.\\n\",\n",
        "            \"niente e meglio di fare quello che ti pare. e poi, ti sto dicendo che sei grande abbastanza.\\n\",\n",
        "            \"non hai nulla da fare, tutti i giorni, se non stai cercando di fare tutto cio che e necessario. ( norman bates )\\n\",\n",
        "            \"lo ho fatto perche sapevo che dovevo diventare uno, che lo avevo gia fatto e che avrei fallito quando ho capito che dovevo diventare uno.\\n\",\n",
        "            \"non e questo l ’ obiettivo a cui in realta sto mirando, sebbene sia quello che cerco sempre di raggiungere. ( joshua reynolds )\\n\"\n",
        "            ]\n",
        "\n",
        "for s in x:\n",
        "  print(s, end='')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "se dirigi gli affari potresti non poter avere le raffinerie. ( j. schuller )\n",
            "se vuoi davvero fare una cosa, e meglio se la smetti di farla. ( thomas edison )\n",
            "(... )... (... ) ( michael schaferman )\n",
            "( se non vuoi essere con un cucchiaino in mano ), devi concentrarti su chi vuoi veramente essere. ( ra )\n",
            "a scrivere e a leggere le parole. ( anonimo )... da dove iniziare?\n",
            "( ( huai ) ) ( ( huai ) ) ( huai ) ) ( ( huai ) ) ( ( hua ) ( ) )\n",
            "[ j. k. ] \" so solo che sto lavorando per vincere. \" fidati, vincerai. ( henry j. d williamson ) ( anonimo )\n",
            "quando muori, la vita finisce. non ci resta che aspettare finche non muori, perche non sai cosa ti aspetta ( anonimo )\n",
            "faro del mio meglio per non essere trattato come un fallito. ma finche saro fallito, non lo faro. ( ripeto, ingra ) ( frank lloyd wright )\n",
            "provaci ( anche se non cadi ) sii un eroe. sii forte. sii coraggioso. sii un eroe.\n",
            "se poi ti rifiuti di fare cose buone, ti fermi per sempre. ( smetti di cercare di fare le cose che vuoi fare. )\n",
            "mi piacerebbe trovare un nuovo modo per prepararmi a questa nuova sfida.\n",
            "no, vattene via, paul berry! ( paul berry che canta ) ( peter t. dieter ).\n",
            "moezsen sta provando a diventare ’ li ’ dentro. se stro qualcosa, ‘ allora si manifesta la sua trascendenza ’.\n",
            "niente e meglio di fare quello che ti pare. e poi, ti sto dicendo che sei grande abbastanza.\n",
            "non hai nulla da fare, tutti i giorni, se non stai cercando di fare tutto cio che e necessario. ( norman bates )\n",
            "lo ho fatto perche sapevo che dovevo diventare uno, che lo avevo gia fatto e che avrei fallito quando ho capito che dovevo diventare uno.\n",
            "non e questo l ’ obiettivo a cui in realta sto mirando, sebbene sia quello che cerco sempre di raggiungere. ( joshua reynolds )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gjsqnQscpSh",
        "outputId": "b72547f3-d6a4-4a54-ab20-6fca2ebc0efa"
      },
      "source": [
        "x = [\n",
        "            \"\\n\",\n",
        "            \" che mai non m ’ io coglia ; \\n\",\n",
        "            \" e non abbracci che li si ridesse, \\n\",\n",
        "            \" che piu tempo fece prodente. \\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \" ma vidi io di lo vento che \\n\",\n",
        "            \" del son s ’ accesi io : \\n\",\n",
        "            \" per tanto piacer che questo venisse il triscio ». \\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \" ma gia di queste le zanne \\n\",\n",
        "            \" sonn piu, si malicce, \\n\",\n",
        "            \" che prima l ’ occhio non era in ciel ; \\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \" vedi, se tu vedi, che la terra s ’ arresta, \\n\",\n",
        "            \" a te e a questo mondo \\n\",\n",
        "            \" c ’ e ’ l mondo che si drizza ». \\n\",\n",
        "            \"\\n\",\n",
        "            \"e tornar per le foci richiudendo la gola, \\n\",\n",
        "            \" si che non se ne andassero, \\n\",\n",
        "            \" mi volsi al petto e a li squarci. \\n\",\n",
        "            \"\\n\",\n",
        "            \"e io, che mi convivo \\n\",\n",
        "            \" dentro e fuori, venia a me, \\n\",\n",
        "            \" e vidi la prima vista \\n\",\n",
        "            \" che la mente m ’ avea piu piena. \\n\",\n",
        "            \"\\n\",\n",
        "            \"venne poi innanzi a me la mia mente, \\n\",\n",
        "            \" per molti anni, e non fu, \\n\",\n",
        "            \" benche non fosse, \\n\",\n",
        "            \" che non fosse in me alcuna virtu ». \\n\",\n",
        "            \"\\n\",\n",
        "            \"e disse a me : ‘ e tu? ’ \\n\",\n",
        "            \" piu in la che vidi, piu non si facea ; \\n\",\n",
        "            \" questo e ’ l padre mio, che e con me ». \\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \" e cato e cato, e in lui \\n\",\n",
        "            \" si fece ’ l uno e un altro, \\n\",\n",
        "            \" si che ’ l le membra e lo spirito movea ». \\n\",\n",
        "            \"\\n\",\n",
        "            \"\\n\",\n",
        "            \" sappi pero che la tua mente e buona, \\n\",\n",
        "            \" che si fa la volonta di dio, \\n\",\n",
        "            \" com ’ e stata fatta l ’ arte del mondo, \\n\",\n",
        "            \" che non e morta. \\n\",\n",
        "            \"\\n\",\n",
        "            \"“ e ’ l viso mio “ chinato ”, \\n\",\n",
        "            \" e ’ l vidi correr dietro a me, \\n\",\n",
        "            \" si tentenno e disse : « loco, loco! ».\\n\",\n",
        "          ]\n",
        "for s in x:\n",
        "  print(s, end='')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " che mai non m ’ io coglia ; \n",
            " e non abbracci che li si ridesse, \n",
            " che piu tempo fece prodente. \n",
            "\n",
            "\n",
            " ma vidi io di lo vento che \n",
            " del son s ’ accesi io : \n",
            " per tanto piacer che questo venisse il triscio ». \n",
            "\n",
            "\n",
            " ma gia di queste le zanne \n",
            " sonn piu, si malicce, \n",
            " che prima l ’ occhio non era in ciel ; \n",
            "\n",
            "\n",
            " vedi, se tu vedi, che la terra s ’ arresta, \n",
            " a te e a questo mondo \n",
            " c ’ e ’ l mondo che si drizza ». \n",
            "\n",
            "e tornar per le foci richiudendo la gola, \n",
            " si che non se ne andassero, \n",
            " mi volsi al petto e a li squarci. \n",
            "\n",
            "e io, che mi convivo \n",
            " dentro e fuori, venia a me, \n",
            " e vidi la prima vista \n",
            " che la mente m ’ avea piu piena. \n",
            "\n",
            "venne poi innanzi a me la mia mente, \n",
            " per molti anni, e non fu, \n",
            " benche non fosse, \n",
            " che non fosse in me alcuna virtu ». \n",
            "\n",
            "e disse a me : ‘ e tu? ’ \n",
            " piu in la che vidi, piu non si facea ; \n",
            " questo e ’ l padre mio, che e con me ». \n",
            "\n",
            "\n",
            " e cato e cato, e in lui \n",
            " si fece ’ l uno e un altro, \n",
            " si che ’ l le membra e lo spirito movea ». \n",
            "\n",
            "\n",
            " sappi pero che la tua mente e buona, \n",
            " che si fa la volonta di dio, \n",
            " com ’ e stata fatta l ’ arte del mondo, \n",
            " che non e morta. \n",
            "\n",
            "“ e ’ l viso mio “ chinato ”, \n",
            " e ’ l vidi correr dietro a me, \n",
            " si tentenno e disse : « loco, loco! ».\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1ywKCAnQ9Hs"
      },
      "source": [
        "## Example 2 - Dante's Divine Comedy\n",
        "\n",
        "In this example we will train our own neural-poet!\n",
        "As before we will start from an italian model https://huggingface.co/dbmdz/bert-base-italian-uncased.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "2e2995a2d4264584bd539fdce2024591",
            "1f08a76d943e40d7ba9ca248f8a0c97f",
            "6ee42ecf2e7e413d9b06c9a2349007ec",
            "60700a3e7b88407b8013f644ebc09b60",
            "c5c5ede358cb43a1acf320c29458ad59",
            "ec57be0f75ea4180ab0d3722aea333c2",
            "9795382e0017498e80299558fc697be0",
            "4b6c95e071874a9d912649d3e3fd04f0",
            "592df71ef32c4b8da1075bb34fa84de2",
            "eb39b90e60f74d9daafd320718806d79",
            "c013a45f17ec4cee9f0f47da84dd2441",
            "2d61b5d0409d49ebae8ce6a3b05d7788",
            "c8250756212e4cda997bb8eb8d1cf355",
            "08522f389bce4dd99a82477a0096c488",
            "3f2017a96a6a4940bd383aa2dae51ac9",
            "1166a28bdb554cb19e3549b6c4d6c6cf",
            "34dee349bb764add93b48cfd8e4a7530",
            "e28b64e42e2b4fe1993b6a48fa71057b",
            "84db804f7545448eb867e2d662f56a9c",
            "fd92d25a59f3425abf65a1a205fd5bdd",
            "d755beaf464f44ce9c54f281c187a200",
            "871d27b1f6de4546a75c6464931db33b",
            "6284b64ff4ca4c4aa20f0e1ee32c2f88",
            "02f314b0181640f0909752b54402155f",
            "77cfd732fc5b4474937181a6e1f7259f",
            "a53be2098541401d90c450fe2106b486",
            "2bdf6e5ab668489b839cd29233141514",
            "f4ee919cd8e04b25bda596ac22fa6e1c",
            "08a242d04efa43ba9b783a8fabcfe40c",
            "e4cc103b69f74a76a57f97325545e8b1",
            "81875f4d54224a2a8118b3aad655bce5",
            "5d06329175d842fbad875bc6f58d29ea",
            "56829d48aa974193b461fa93f39fd433",
            "56d242fa97fe4be6b5e05ee0733126c1",
            "9eb48f966f58441fad89d8541a29d713",
            "dda70c58fd5d4a0e85fdac35f36367ce",
            "af796fac21d4451cbd813e6c3b9a469a",
            "d0c7383745b04b4aab5b51515d719b4e",
            "cdcf640b3e254eb18ce572be73fe3781",
            "88203639fad24edb944f7ecbd686ec00",
            "ec1a407f7c7745d7a6f9ad80ac7f2eb4",
            "5dcf6c09a009494d9074dc14bb0ddc15",
            "612ce61627734504a42d6b48b0058ccd",
            "33f292e16a79404ebca121a4dd864f46"
          ]
        },
        "id": "BTNAL3tPhF-j",
        "outputId": "87e4f709-d1af-44f7-bf0c-e19a739dafdc"
      },
      "source": [
        "it_bert_model = BertTextGenerator(\"dbmdz/bert-base-italian-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e2995a2d4264584bd539fdce2024591",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d61b5d0409d49ebae8ce6a3b05d7788",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6284b64ff4ca4c4aa20f0e1ee32c2f88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56d242fa97fe4be6b5e05ee0733126c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAuxWvlohOlX"
      },
      "source": [
        "Then we need Dante's Divine Comedy. We can download it from this repo (https://github.com/dlang/druntime.git)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQr1eKzTFJdA",
        "outputId": "10ffc2ab-0145-4e91-8fed-17ef96518074"
      },
      "source": [
        "!curl https://raw.githubusercontent.com/dlang/druntime/master/benchmark/extra-files/dante.txt > dante.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  543k  100  543k    0     0  6252k      0 --:--:-- --:--:-- --:--:-- 6252k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f34hxUsIMgc",
        "outputId": "0513126e-88fe-424e-8ba5-82ae7fde073c"
      },
      "source": [
        "path_dante = '/content/dante.txt'\n",
        "\n",
        "with open(path_dante, 'r') as f_dante:\n",
        "  i = 0\n",
        "  while i < 30:\n",
        "    print(f_dante.readline(), end='')\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LA DIVINA COMMEDIA\n",
            "di Dante Alighieri\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "INFERNO\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Inferno · Canto I\n",
            "\n",
            "\n",
            "Nel mezzo del cammin di nostra vita\n",
            "mi ritrovai per una selva oscura,\n",
            "ché la diritta via era smarrita.\n",
            "\n",
            "Ahi quanto a dir qual era è cosa dura\n",
            "esta selva selvaggia e aspra e forte\n",
            "che nel pensier rinova la paura!\n",
            "\n",
            "Tant’ è amara che poco è più morte;\n",
            "ma per trattar del ben ch’i’ vi trovai,\n",
            "dirò de l’altre cose ch’i’ v’ho scorte.\n",
            "\n",
            "Io non so ben ridir com’ i’ v’intrai,\n",
            "tant’ era pien di sonno a quel punto\n",
            "che la verace via abbandonai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ubBbpQIi5D"
      },
      "source": [
        "Above are printed the first 4 tercets of Dante's masterpiece. The Divine Comedy is divided in three cantiche: Inferno (Hell), Purgatorio (Purgatory), and Paradiso (Paradise) – each consisting of 33 cantos.\n",
        "\n",
        "Tipically a model is trained on a text file considering all the lines on at time, however as we can see this file contains a lot of empty lines and intestations. Moerover considering a line at time we break the tercets, that are the 3-lines structure of which the poem is composed.\n",
        "\n",
        "Our goal is to train a model able to produce small poems. So a better idea would be to clean the file and consider tercets instead of single lines.\n",
        "\n",
        "To do this it can come in handy the `Formatter` class present in  `NeuralTextGenerator.textprocessing` with which we can define the pattern for the lines that we want to extract. Moreover it allows to define a set of tokens that we want to preserve before and after the tokenization. In this case for example, to let BERT learn the tercet structure is important that it learns also where to place the newlines ('\\n') characters. To do this we simply need to specify a list of `replace_tokens` and define the `unused_type`. This can be the most tricky part since there is not a conventional way and each BERT model can use a different set of tokens. For example 'bert-base-uncased' used '`[unused-1], [unused-2], etc...` while 'bert-base-italian-uncased' (the model we are using) uses `unused1, unused2, etc...`\n",
        "\n",
        "Note:\n",
        "Each token in the `replace_tokens` is replaced with an unused token before the tokenization and then replaced back after the generation of the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjJrD8_ngyMB",
        "outputId": "b326d5be-43c0-4cf3-f995-f565155a5e8c"
      },
      "source": [
        "from neuraltextgen.textprocessing import Formatter\n",
        "\n",
        "tercet_pattern = '\\n((.)+\\n){3}'\n",
        "formatter = Formatter(replace_tokens=['\\n'], unused_type='unusedi')\n",
        "lines = formatter.format(path_dante, pattern = tercet_pattern)\n",
        "\n",
        "for i,l in enumerate(lines[:5]):\n",
        "  print(f\"Tercet {i+1}: {l}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tercet 1:  unused1 Nel mezzo del cammin di nostra vita unused1 mi ritrovai per una selva oscura, unused1 ché la diritta via era smarrita. unused1 \n",
            "Tercet 2:  unused1 Ahi quanto a dir qual era è cosa dura unused1 esta selva selvaggia e aspra e forte unused1 che nel pensier rinova la paura! unused1 \n",
            "Tercet 3:  unused1 Tant’ è amara che poco è più morte; unused1 ma per trattar del ben ch’i’ vi trovai, unused1 dirò de l’altre cose ch’i’ v’ho scorte. unused1 \n",
            "Tercet 4:  unused1 Io non so ben ridir com’ i’ v’intrai, unused1 tant’ era pien di sonno a quel punto unused1 che la verace via abbandonai. unused1 \n",
            "Tercet 5:  unused1 Ma poi ch’i’ fui al piè d’un colle giunto, unused1 là dove terminava quella valle unused1 che m’avea di paura il cor compunto, unused1 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfcAIvkpOJMl"
      },
      "source": [
        "As we can see now the tercets have been transformed into simple lines and the '\\n' characters have been replaced with 'unused1' so that the '\\n' are not removed by the tokenizer and BERT will be able to learn the position of 'unused1' in the text.\n",
        "\n",
        "Finally we need to finetune the model. This is very simple, we only need to pass the lines that we have gathered before and if we want specify the hyperparameters of the finetuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxEhQ42Bhhql",
        "outputId": "10c512bc-03d3-4887-cc90-b05036d16338"
      },
      "source": [
        "it_bert_model.finetune(lines, epochs=4, optimizer_parameters = dict(lr=5e-5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of    148.    Elapsed: 0:00:21.\n",
            "  Batch    50  of    148.    Elapsed: 0:00:41.\n",
            "  Batch    75  of    148.    Elapsed: 0:01:02.\n",
            "  Batch   100  of    148.    Elapsed: 0:01:22.\n",
            "  Batch   125  of    148.    Elapsed: 0:01:43.\n",
            "\n",
            "  Average training loss: 2.60\n",
            "  Training epcoh took: 0:02:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of    148.    Elapsed: 0:00:20.\n",
            "  Batch    50  of    148.    Elapsed: 0:00:41.\n",
            "  Batch    75  of    148.    Elapsed: 0:01:01.\n",
            "  Batch   100  of    148.    Elapsed: 0:01:21.\n",
            "  Batch   125  of    148.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 2.01\n",
            "  Training epcoh took: 0:02:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of    148.    Elapsed: 0:00:20.\n",
            "  Batch    50  of    148.    Elapsed: 0:00:41.\n",
            "  Batch    75  of    148.    Elapsed: 0:01:01.\n",
            "  Batch   100  of    148.    Elapsed: 0:01:21.\n",
            "  Batch   125  of    148.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 1.89\n",
            "  Training epcoh took: 0:02:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of    148.    Elapsed: 0:00:20.\n",
            "  Batch    50  of    148.    Elapsed: 0:00:41.\n",
            "  Batch    75  of    148.    Elapsed: 0:01:01.\n",
            "  Batch   100  of    148.    Elapsed: 0:01:21.\n",
            "  Batch   125  of    148.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 1.81\n",
            "  Training epcoh took: 0:02:00\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:08:01 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5mAjhZyVAz5"
      },
      "source": [
        "Now the fun part!\n",
        "Our model is finetuned and ready to generate some beautiful poems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODfKskR37Dk",
        "outputId": "a495895c-f073-4151-97e6-c0d5ca16edb9"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'std_len':4,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':200\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " che mai non m ’ io coglia ; \n",
            " e non abbracci che li si ridesse, \n",
            " che piu tempo fece prodente. \n",
            "\n",
            "\n",
            " ma vidi io di lo vento che \n",
            " del son s ’ accesi io : \n",
            " per tanto piacer che questo venisse il triscio ». \n",
            "\n",
            "\n",
            " ma gia di queste le zanne \n",
            " sonn piu, si malicce, \n",
            " che prima l ’ occhio non era in ciel ; \n",
            "\n",
            "\n",
            " \n",
            " fu tra li occhi contenti \n",
            " e vidi \n",
            " tutti si tra loro cominciar in dietro \n",
            " feretro a e fuor d ’ orbi. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh-awpm_WaAM",
        "outputId": "ef4b750d-d7c6-41b5-8c56-1d8721f3a701"
      },
      "source": [
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'std_len':4,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':150\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "al foco di lui perde voce, che ponzio, fama per cui poeta \n",
            " non puo fregiarla o sua pena. \n",
            "\n",
            "\n",
            " si ’ m terra in la dove si parte, fa ragion e varia, \n",
            " di grazia e suo tempso sapea : \n",
            "\n",
            "\n",
            " da come m ’ e noto \n",
            " che del mio caro vien quel convien, \n",
            " da quel che pur e pur, \n",
            "\n",
            "sappi che l ’ arte mia e si santa \n",
            " per fare la guerra che la coscienza \n",
            " gia har cristo in mano la mente. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KosRmjSrbAHu",
        "outputId": "3c441f5f-b310-4e1c-edd9-aec58ac1ebac"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':35, \n",
        "              'generation_method':'sequential',\n",
        "              'max_iter':500,\n",
        "              'burnin':400,\n",
        "              'top_k':100\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " vedi, se tu vedi, che la terra s ’ arresta, \n",
            " a te e a questo mondo \n",
            " c ’ e ’ l mondo che si drizza ». \n",
            "\n",
            "e tornar per le foci richiudendo la gola, \n",
            " si che non se ne andassero, \n",
            " mi volsi al petto e a li squarci. \n",
            "\n",
            "e io, che mi convivo \n",
            " dentro e fuori, venia a me, \n",
            " e vidi la prima vista \n",
            " che la mente m ’ avea piu piena. \n",
            "\n",
            "venne poi innanzi a me la mia mente, \n",
            " per molti anni, e non fu, \n",
            " benche non fosse, \n",
            " che non fosse in me alcuna virtu ». \n",
            "\n",
            "CPU times: user 22 s, sys: 36.1 ms, total: 22 s\n",
            "Wall time: 22 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQbt00pJagrR",
        "outputId": "8b997d49-1610-4128-f23c-3bdcc9951901"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'generation_method':'sequential',\n",
        "              'max_iter':500,\n",
        "              'burnin':400,\n",
        "              'top_k':100\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ov ’ aprii li occhi, la tua vista, e la tua vedetta, \n",
            " vidi il sole e la luce del mondo che ti guarda. \n",
            "\n",
            "\n",
            " e per la prima volta \n",
            " queste son le genti che son vicine, \n",
            " nulla e nullo a quel che non si disgiunge ». \n",
            "\n",
            "\n",
            " per far si che, di volto in volto, \n",
            " dietro al viso mio mi guardava, \n",
            " poco a poco mi venisse a seguir umilmente. \n",
            "\n",
            "« non fui di quella donna, ma quella che s ’ empia, \n",
            " che per la sua vita avea di fronte a se la vergogna ». \n",
            "\n",
            "CPU times: user 21.6 s, sys: 48.3 ms, total: 21.6 s\n",
            "Wall time: 21.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYxH1HHEWizn",
        "outputId": "b00a5a23-aab8-4aa9-ab30-c95ea80dce57"
      },
      "source": [
        "\n",
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'generation_method':'attention',\n",
        "              'max_iter':1000,\n",
        "              'burnin':850,\n",
        "              'top_k':100\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "disse : « questo e tempo di tenebra \n",
            " di viver e di morte \n",
            " si che si vive e si si che si vive ». \n",
            "\n",
            "e io m ’ unisco ad esse, \n",
            " si ch ’ a creder mi fa creder, \n",
            " e mi fa lor sembiante. \n",
            "\n",
            "\n",
            " non perdendo in me la paura \n",
            " che, per quanto mi dolse, \n",
            " pur di non aver paura mi rispuose. \n",
            "\n",
            "\n",
            " ma se tu credi a me, crederai \n",
            " a la mia fede, \n",
            " non a la compagnia, ma a creder meco. \n",
            "\n",
            "CPU times: user 33.6 s, sys: 61 ms, total: 33.6 s\n",
            "Wall time: 33.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWTmCvKsWixS",
        "outputId": "a7e14b22-c2ff-4c7a-f343-a73ab86cc8bc"
      },
      "source": [
        "# Don't delete\n",
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':35, \n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              'burnin':350,\n",
        "              'top_k':100\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e disse a me : ‘ e tu? ’ \n",
            " piu in la che vidi, piu non si facea ; \n",
            " questo e ’ l padre mio, che e con me ». \n",
            "\n",
            "\n",
            " e cato e cato, e in lui \n",
            " si fece ’ l uno e un altro, \n",
            " si che ’ l le membra e lo spirito movea ». \n",
            "\n",
            "\n",
            " sappi pero che la tua mente e buona, \n",
            " che si fa la volonta di dio, \n",
            " com ’ e stata fatta l ’ arte del mondo, \n",
            " che non e morta. \n",
            "\n",
            "“ e ’ l viso mio “ chinato ”, \n",
            " e ’ l vidi \n",
            " correr dietro a me, \n",
            " si tentenno e disse : « loco, loco! ».\n",
            "CPU times: user 22.6 s, sys: 38.4 ms, total: 22.6 s\n",
            "Wall time: 22.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2uyqCYkWivE",
        "outputId": "ba4f6ab1-3a0b-409d-beb2-e2e0a7280dca"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'std_len':4,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              'burnin':350,\n",
        "              'top_k':100\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "si, ma chi crolla \n",
            " non vede, ne chi non vede, \n",
            " ne chi non vede, ne chi non agora. \n",
            "\n",
            "\n",
            " ma sappi che ’ l segno che ti fa felice \n",
            " e il segno, \n",
            " che piu ti piace piu che l ’ ombra. \n",
            "\n",
            "\n",
            " e lei avea la voce molto alta, \n",
            " quella che mi disse : \n",
            " « per me la bonta e morta ». \n",
            "\n",
            "e ’ colui che dice, e che si fa \n",
            " per lo parlar suo, \n",
            " e per le sue parole la mente muta. \n",
            "\n",
            "CPU times: user 16.6 s, sys: 49.3 ms, total: 16.6 s\n",
            "Wall time: 16.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Rlh_X-Wisq",
        "outputId": "7467b0ff-479d-4c2c-eb19-fc5f4a88bab3"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'std_len':4,\n",
        "              'generation_method':'attention',\n",
        "              'max_iter':500,\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e come, ritornando al foglio, \n",
            " son anni che son vive ; e la donna che queste benedette ha, \n",
            " sanza, son due ; \n",
            "\n",
            "« voi, mio frate, fatto loco, \n",
            " eram, per cui beato non eran fatto ; \n",
            " e fuil ’ eserciti seco seco \n",
            "\n",
            "ma lettor, si che si dicen ; \n",
            " che le note, dette, son queste ; \n",
            " quanto si vede in foco e tannello. \n",
            "\n",
            "\n",
            " mose ’ m ’ acer sotto ciascun manto con questo occhio, \n",
            " che vede il mondo in quel modo \n",
            " e quel che a lui piace. \n",
            "\n",
            "CPU times: user 21.9 s, sys: 71.3 ms, total: 22 s\n",
            "Wall time: 21.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "velw9be9Wiqp",
        "outputId": "55058274-7e4d-4e7a-e564-83572410ac98"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 4, \n",
        "              'batch_size':4, \n",
        "              'avg_len':30, \n",
        "              'std_len':4,\n",
        "              'generation_method':'parallel',\n",
        "              'max_iter':500,\n",
        "              'burnin':400,\n",
        "              'seed_text':\"Nel mezzo\"\n",
        "              }\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/dante_generated.txt', **parameters)\n",
        "\n",
        "for s in formatter.unformat(sents):\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nel mezzo avea preso un poco d ’ acqua, \n",
            " che di fachio impressava, \n",
            " si che ’ nvidia non avevan le foglie. \n",
            "\n",
            "nel mezzo m ’ accorse, dicendo : pria, ti vidi lui, in su, e de l ’ ombra di livio \n",
            " io non mi trasse. \n",
            "\n",
            "nel mezzo e ’ l ’ arcor non si trova \n",
            " che e piu lungo de la vita, \n",
            " che non puo esser piu lungo di quel che non si trova. \n",
            "\n",
            "nel mezzo l ’ umana natura si trasmuta, \n",
            " di qua insieme a noi, \n",
            " per quel che tu vedi, \n",
            " che non vien per te ». \n",
            "\n",
            "CPU times: user 21.8 s, sys: 54.5 ms, total: 21.9 s\n",
            "Wall time: 21.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpbtSQ4vWia-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t8HU-CGlLF4",
        "outputId": "e4fa4817-d66e-41fd-da18-273ed604a504"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              # 'top_k': 40,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              # 'seed_text': \"Nel mezzo del cammin di nostra vita \\n\",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    for k,v in it_bert_model.format_tokenizer.dict_token_replace.items():\n",
        "        s = s.replace(v.strip(), k)\n",
        "    \n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " si, io rimasi, da tanto in tanto in giuso in giuso \n",
            " essendo l ’ andar d ’ una godenza \n",
            "\n",
            "\n",
            " non e come cio che non puo altrui, \n",
            " che non puo puo \n",
            " riceversi non se a l ’ amore suo stesso. \n",
            "\n",
            "\n",
            " e che forma di addormento \n",
            " in nulla e del tutto smarrito, \n",
            " che non riconosce l ’ uomo e non si piega \n",
            "\n",
            "CPU times: user 6.52 s, sys: 15.5 ms, total: 6.53 s\n",
            "Wall time: 6.54 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff3y2ORssP0b",
        "outputId": "09fb6529-d421-4895-8a8d-1c19f30978f1"
      },
      "source": [
        "sfor s in sents:\n",
        "    for k,v in it_bert_model.format_tokenizer.dict_token_replace.items():\n",
        "        s = s.replace(v.strip(), k)\n",
        "    print(s)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " la nostra natura umana e gia esistita, \n",
            " ma mai conforme al suo comandamento \n",
            " qual e a colui che tu vedi e a te di quando in quando ». \n",
            "\n",
            "\n",
            " prima discende quindi d ’ un monte ; \n",
            " poi l ’ onde dolor la tiene a se ; \n",
            " suo dolor tace se non e d ’ un bove. \n",
            "\n",
            "\n",
            " poi che o totti era vinto, o a me dato \n",
            " ben ben mi era gia dato, \n",
            " ed era si ch ’ io in tutto cio non m ’ era visto \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApJYmDyDnNA9",
        "outputId": "9f09c202-8a9f-421b-a05a-e033095a135e"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 3,  # 1000\n",
        "              'batch_size': 3,  # 50\n",
        "              'avg_len':40,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              # 'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              'seed_text': \"\",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "  for k,v in it_bert_model.formatter.dict_token_replace.items():\n",
        "    s = s.replace(v, k)\n",
        "\n",
        "  print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " fallazion ove troppo si ragione, \n",
            " saper, ch ’ ogne parte \n",
            " che ritornasse, si luceva \n",
            " secondo voglie tutte ; \n",
            "\n",
            "\n",
            " si poi che prima piacque, \n",
            " e poi lascio esser morto ; \n",
            " poi mencon el al disia, tal ch ’ accese una guiccia \n",
            "\n",
            "\n",
            " si spene quel godebrano » ; \n",
            " ’ z ’ favella mestieraa, e, come, \n",
            " s elli, si la mente, \n",
            "\n",
            "CPU times: user 6.39 s, sys: 15.9 ms, total: 6.4 s\n",
            "Wall time: 6.39 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqoZ0agyDQ-U"
      },
      "source": [
        "## Example 3 - Italian tweets - (Generation with sentiment)\n",
        "\n",
        "The last example will show how to generate text with a given sentiment!\n",
        "We will focus on a specific domain that are italian tweets about football.\n",
        "\n",
        "We can start as usual preparing the model that we will finetune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P03dbWiqsjU",
        "outputId": "f41a058d-58c6-4ef0-ea53-ab20a733a76e"
      },
      "source": [
        "it_bert_model = BertTextGenerator(\"dbmdz/bert-base-italian-uncased\", \n",
        "                                  use_fast=False)\n",
        "tokenizer = it_bert_model.tokenizer\n",
        "model = it_bert_model.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHouoBcQrC6V"
      },
      "source": [
        "Then we need to download the dataset on which we will finetune the model, from https://github.com/charlesmalafosse/open-dataset-for-sentiment-analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi1Fw6Hz0VI2"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nCTObf5kbSp",
        "outputId": "9997bdd8-86af-44a4-97d4-aeff88e69b4e"
      },
      "source": [
        "!curl \"https://raw.githubusercontent.com/charlesmalafosse/open-dataset-for-sentiment-analysis/master/betsentiment-IT-tweets-sentiment-players.zip\" > '/content/betsentiment-IT-tweets-sentiment-players.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 22.4M  100 22.4M    0     0  54.0M      0 --:--:-- --:--:-- --:--:-- 54.0M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ReyWlaRlHso",
        "outputId": "bec74cfb-55fb-4ac5-a960-9d0eb5005084"
      },
      "source": [
        "!unzip '/content/betsentiment-IT-tweets-sentiment-players.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/betsentiment-IT-tweets-sentiment-players.zip\n",
            "replace betsentiment-IT-tweets-sentiment-players.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KyoRWYzmDox"
      },
      "source": [
        "This dataset contains italian tweets about football. Each tweets carry a sentiment score for each one of four sentiment label [POSITIVE, NEGATIVE, MIXED, NEUTRAL] and a sentiment that is the sentiment label with the highest score. For semplicity we will focus only on POSITIVE and NEGATIVE labels that are the vast majority of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "v3tW2eZIDSkM",
        "outputId": "d18100b3-7a45-489f-f7ba-eda5c011e2c5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/betsentiment-IT-tweets-sentiment-players.csv', engine='python',encoding='cp1252')\n",
        "df = df[df.sentiment != 'NEUTRAL']\n",
        "df = df[df.sentiment != 'MIXED']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_date_created</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>language</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2018-06-30T09:10:30</td>\n",
              "      <td>1012986724002226177</td>\n",
              "      <td>@LichtsteinerSte @juventusfc Grazie di tutto,#...</td>\n",
              "      <td>it</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>{\"Neutral\":0.4109617769718170166015625,\"Negati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2018-07-07T08:38:23.456000</td>\n",
              "      <td>1015515359703699456</td>\n",
              "      <td>Scusami @Cristiano, potresti dirci se oggi arr...</td>\n",
              "      <td>it</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>{\"Neutral\":0.266156733036041259765625,\"Negativ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2018-07-03T09:40:30.897000</td>\n",
              "      <td>1014081437639888897</td>\n",
              "      <td>@NonEvoluto @PReina25 @MassMirabelli Max nelle...</td>\n",
              "      <td>it</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>{\"Neutral\":0.14758466184139251708984375,\"Negat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2018-05-21T12:52:10</td>\n",
              "      <td>998546995693457409</td>\n",
              "      <td>@PasquAmatoJ8 @MarioMandzukic9 @G_Higuain @juv...</td>\n",
              "      <td>it</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>{\"Neutral\":0.4223925173282623291015625,\"Negati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2018-07-10T21:55:48.464000</td>\n",
              "      <td>1016803199724990464</td>\n",
              "      <td>Nonostante l'odio sportivo verso la @juventusf...</td>\n",
              "      <td>it</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>{\"Neutral\":0.107764475047588348388671875,\"Nega...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            tweet_date_created  ...                                    sentiment_score\n",
              "11         2018-06-30T09:10:30  ...  {\"Neutral\":0.4109617769718170166015625,\"Negati...\n",
              "13  2018-07-07T08:38:23.456000  ...  {\"Neutral\":0.266156733036041259765625,\"Negativ...\n",
              "28  2018-07-03T09:40:30.897000  ...  {\"Neutral\":0.14758466184139251708984375,\"Negat...\n",
              "44         2018-05-21T12:52:10  ...  {\"Neutral\":0.4223925173282623291015625,\"Negati...\n",
              "45  2018-07-10T21:55:48.464000  ...  {\"Neutral\":0.107764475047588348388671875,\"Nega...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "286BK49ibpOu",
        "outputId": "01a60185-7290-44e6-8546-3c805ba30ed2"
      },
      "source": [
        "np.unique(df.sentiment, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['NEGATIVE', 'POSITIVE'], dtype=object), array([ 6542, 23552]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6G3xJ6ImSp6"
      },
      "source": [
        "We can clearly see that even considering only POSITIVE and NEGATIVE sentiments, the dataset is still very umbalanced. We will consider only 6000 tweets for each sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOccsVRnYOe8"
      },
      "source": [
        "positive_tweets_mask = df.sentiment == 'POSITIVE'\n",
        "negative_tweets_mask = df.sentiment == 'NEGATIVE'\n",
        "\n",
        "ids_positive = df.index[positive_tweets_mask].to_list()[:6000]\n",
        "ids_negative = df.index[negative_tweets_mask].to_list()[:6000]\n",
        "df = df.loc[ids_positive+ids_negative]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijxZTNNuEjFq",
        "outputId": "43bf08a1-64bc-49d6-ca3f-1ea585da7bc0"
      },
      "source": [
        "tweets=  df.tweet_text.to_list()\n",
        "sentiment = df.sentiment.to_list()\n",
        "for s, S in zip(tweets[:5], sentiment[:5]):\n",
        "  print(f\"[{S}]:\\n {s}\\n\")\n",
        "\n",
        "print()\n",
        "\n",
        "tweets=  df.tweet_text.to_list()\n",
        "sentiment = df.sentiment.to_list()\n",
        "for s, S in zip(tweets[6000:6005], sentiment[6000:6005]):\n",
        "      print(f\"[{S}]:\\n {s}\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POSITIVE]:\n",
            " @LichtsteinerSte @juventusfc Grazie di tutto,#SwissExpress,sono stati 7 anni indimenticabili fatti di vittorie,sconfitte (poche!),enormi gioie e tante incazzature in campo con gli arbitri.? Sono stati 7 anni da #MY7H.\n",
            "Mi mancherai.???\n",
            "\n",
            "[POSITIVE]:\n",
            " Scusami @Cristiano, potresti dirci se oggi arrivi a Torino?\n",
            "Va bene pure un’ autocertificazione, tanto siamo in Italia... \n",
            "@juventusfc\n",
            "\n",
            "[POSITIVE]:\n",
            " @NonEvoluto @PReina25 @MassMirabelli Max nelle cessioni è top.. negli acquisti può migliorare\n",
            "\n",
            "[POSITIVE]:\n",
            " @PasquAmatoJ8 @MarioMandzukic9 @G_Higuain @juventusfc Tanti auguri Gonzalo\n",
            "\n",
            "[POSITIVE]:\n",
            " Nonostante l'odio sportivo verso la @juventusfc, che grande colpo portare @Cristiano in @SerieA_TIM! Spero il @sscnapoli risponda a questo colpo!\n",
            "\n",
            "\n",
            "[NEGATIVE]:\n",
            " @TheMoralyzer @nicos_moriello @StanisLaRochele @Vivo_e_vegeto @DiegoMontuori @sscnapoli @douglascosta È inutile che cerchiate di far credere che non contiamo un cazzo, perché vi mettete a cantare i cori del Napoli “rivisitati” allo Stadium a cazzo di cane... ? Poi se vuoi negarlo fai ?\n",
            "\n",
            "[NEGATIVE]:\n",
            " @RobMaida @OfficialASRoma @CorSport @LorePelle7 Purtroppo la fragilità dei muscoli è sempre stato il problema di questo ragazzo , anche a #Sassuolo ha avuto molti ( troppi ) infortuni muscolari. Peccato\n",
            "\n",
            "[NEGATIVE]:\n",
            " #AtalantaJuve 2-2... non ci battete giocando 40 minuti in 11 contro 10...non ci battete con arbitraggio a senso unico..gol annullati...non ci battete con @Cristiano 60 minuti in panchina...non ci battete nemmeno se giochiamo bendati.. ?????????#FinoAllaFine #Ronaldo https://t.co/4jrspllqBF\n",
            "\n",
            "[NEGATIVE]:\n",
            " @RollingStoneita @Cristiano @juventusfc Avete la lingua sporca di merda\n",
            "\n",
            "[NEGATIVE]:\n",
            " #FranciaVsArgentina #FifaWorldCup2018 @mascherano è un giocatore che mi è sempre piaciuto ma che mi sembra ormai improponibile a questi livelli\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0DdxvHu0vg8",
        "outputId": "caadc2ae-05cb-4b84-8294-b3f88143685c"
      },
      "source": [
        "print(tweets[0].split())\n",
        "print(tokenizer.tokenize(tweets[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['@LichtsteinerSte', '@juventusfc', 'Grazie', 'di', 'tutto,#SwissExpress,sono', 'stati', '7', 'anni', 'indimenticabili', 'fatti', 'di', 'vittorie,sconfitte', '(poche!),enormi', 'gioie', 'e', 'tante', 'incazzature', 'in', 'campo', 'con', 'gli', 'arbitri.?', 'Sono', 'stati', '7', 'anni', 'da', '#MY7H.', 'Mi', 'mancherai.???']\n",
            "['@', 'li', '##cht', '##stein', '##ers', '##te', '@', 'juventus', '##fc', 'grazie', 'di', 'tutto', ',', '#', 'swiss', '##ex', '##press', ',', 'sono', 'stati', '7', 'anni', 'indimenti', '##cabili', 'fatti', 'di', 'vittorie', ',', 'sconfitte', '(', 'poche', '!', ')', ',', 'enormi', 'gioi', '##e', 'e', 'tante', 'inca', '##zza', '##ture', 'in', 'campo', 'con', 'gli', 'arbi', '##tri', '.', '?', 'sono', 'stati', '7', 'anni', 'da', '#', 'my', '##7', '##h', '.', 'mi', 'manch', '##erai', '.', '?', '?', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igh8cJOTnmTA"
      },
      "source": [
        "Obviously, tweets are full of tags '@' and hashtags '#', that the tokenizer is not able to deal with. Moreover since this dataset is focused on a very specific domain, that is football, that are a lot of terms and names (of players and teams for example, like 'Lichtsteiner' in the exmaple above) that can be focal for the generation but that the tokenizer doesn't know yet.\n",
        "\n",
        "Bert tokenizer gave the possibility to add new tokens. To gather the terms that we want to add we will use a fifa19 dataset that can be downlaoded from here:\n",
        "https://www.kaggle.com/karangadiya/fifa19/download\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "1yOUN3wk_dig",
        "outputId": "f898ec5d-c188-4c12-b343-16e7d941afe3"
      },
      "source": [
        "fifa19_df = pd.read_csv('/content/data.csv')\n",
        "fifa19_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>Photo</th>\n",
              "      <th>Nationality</th>\n",
              "      <th>Flag</th>\n",
              "      <th>Overall</th>\n",
              "      <th>Potential</th>\n",
              "      <th>Club</th>\n",
              "      <th>Club Logo</th>\n",
              "      <th>Value</th>\n",
              "      <th>Wage</th>\n",
              "      <th>Special</th>\n",
              "      <th>Preferred Foot</th>\n",
              "      <th>International Reputation</th>\n",
              "      <th>Weak Foot</th>\n",
              "      <th>Skill Moves</th>\n",
              "      <th>Work Rate</th>\n",
              "      <th>Body Type</th>\n",
              "      <th>Real Face</th>\n",
              "      <th>Position</th>\n",
              "      <th>Jersey Number</th>\n",
              "      <th>Joined</th>\n",
              "      <th>Loaned From</th>\n",
              "      <th>Contract Valid Until</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>LS</th>\n",
              "      <th>ST</th>\n",
              "      <th>RS</th>\n",
              "      <th>LW</th>\n",
              "      <th>LF</th>\n",
              "      <th>CF</th>\n",
              "      <th>RF</th>\n",
              "      <th>RW</th>\n",
              "      <th>LAM</th>\n",
              "      <th>CAM</th>\n",
              "      <th>RAM</th>\n",
              "      <th>LM</th>\n",
              "      <th>...</th>\n",
              "      <th>LB</th>\n",
              "      <th>LCB</th>\n",
              "      <th>CB</th>\n",
              "      <th>RCB</th>\n",
              "      <th>RB</th>\n",
              "      <th>Crossing</th>\n",
              "      <th>Finishing</th>\n",
              "      <th>HeadingAccuracy</th>\n",
              "      <th>ShortPassing</th>\n",
              "      <th>Volleys</th>\n",
              "      <th>Dribbling</th>\n",
              "      <th>Curve</th>\n",
              "      <th>FKAccuracy</th>\n",
              "      <th>LongPassing</th>\n",
              "      <th>BallControl</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>SprintSpeed</th>\n",
              "      <th>Agility</th>\n",
              "      <th>Reactions</th>\n",
              "      <th>Balance</th>\n",
              "      <th>ShotPower</th>\n",
              "      <th>Jumping</th>\n",
              "      <th>Stamina</th>\n",
              "      <th>Strength</th>\n",
              "      <th>LongShots</th>\n",
              "      <th>Aggression</th>\n",
              "      <th>Interceptions</th>\n",
              "      <th>Positioning</th>\n",
              "      <th>Vision</th>\n",
              "      <th>Penalties</th>\n",
              "      <th>Composure</th>\n",
              "      <th>Marking</th>\n",
              "      <th>StandingTackle</th>\n",
              "      <th>SlidingTackle</th>\n",
              "      <th>GKDiving</th>\n",
              "      <th>GKHandling</th>\n",
              "      <th>GKKicking</th>\n",
              "      <th>GKPositioning</th>\n",
              "      <th>GKReflexes</th>\n",
              "      <th>Release Clause</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>158023</td>\n",
              "      <td>L. Messi</td>\n",
              "      <td>31</td>\n",
              "      <td>https://cdn.sofifa.org/players/4/19/158023.png</td>\n",
              "      <td>Argentina</td>\n",
              "      <td>https://cdn.sofifa.org/flags/52.png</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>FC Barcelona</td>\n",
              "      <td>https://cdn.sofifa.org/teams/2/light/241.png</td>\n",
              "      <td>€110.5M</td>\n",
              "      <td>€565K</td>\n",
              "      <td>2202</td>\n",
              "      <td>Left</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Medium/ Medium</td>\n",
              "      <td>Messi</td>\n",
              "      <td>Yes</td>\n",
              "      <td>RF</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Jul 1, 2004</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2021</td>\n",
              "      <td>5'7</td>\n",
              "      <td>159lbs</td>\n",
              "      <td>88+2</td>\n",
              "      <td>88+2</td>\n",
              "      <td>88+2</td>\n",
              "      <td>92+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>92+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>93+2</td>\n",
              "      <td>91+2</td>\n",
              "      <td>...</td>\n",
              "      <td>59+2</td>\n",
              "      <td>47+2</td>\n",
              "      <td>47+2</td>\n",
              "      <td>47+2</td>\n",
              "      <td>59+2</td>\n",
              "      <td>84.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>€226.5M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20801</td>\n",
              "      <td>Cristiano Ronaldo</td>\n",
              "      <td>33</td>\n",
              "      <td>https://cdn.sofifa.org/players/4/19/20801.png</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>https://cdn.sofifa.org/flags/38.png</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>Juventus</td>\n",
              "      <td>https://cdn.sofifa.org/teams/2/light/45.png</td>\n",
              "      <td>€77M</td>\n",
              "      <td>€405K</td>\n",
              "      <td>2228</td>\n",
              "      <td>Right</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>High/ Low</td>\n",
              "      <td>C. Ronaldo</td>\n",
              "      <td>Yes</td>\n",
              "      <td>ST</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Jul 10, 2018</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022</td>\n",
              "      <td>6'2</td>\n",
              "      <td>183lbs</td>\n",
              "      <td>91+3</td>\n",
              "      <td>91+3</td>\n",
              "      <td>91+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>90+3</td>\n",
              "      <td>90+3</td>\n",
              "      <td>90+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>...</td>\n",
              "      <td>61+3</td>\n",
              "      <td>53+3</td>\n",
              "      <td>53+3</td>\n",
              "      <td>53+3</td>\n",
              "      <td>61+3</td>\n",
              "      <td>84.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>€127.1M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>190871</td>\n",
              "      <td>Neymar Jr</td>\n",
              "      <td>26</td>\n",
              "      <td>https://cdn.sofifa.org/players/4/19/190871.png</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>https://cdn.sofifa.org/flags/54.png</td>\n",
              "      <td>92</td>\n",
              "      <td>93</td>\n",
              "      <td>Paris Saint-Germain</td>\n",
              "      <td>https://cdn.sofifa.org/teams/2/light/73.png</td>\n",
              "      <td>€118.5M</td>\n",
              "      <td>€290K</td>\n",
              "      <td>2143</td>\n",
              "      <td>Right</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>High/ Medium</td>\n",
              "      <td>Neymar</td>\n",
              "      <td>Yes</td>\n",
              "      <td>LW</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Aug 3, 2017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022</td>\n",
              "      <td>5'9</td>\n",
              "      <td>150lbs</td>\n",
              "      <td>84+3</td>\n",
              "      <td>84+3</td>\n",
              "      <td>84+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>89+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>...</td>\n",
              "      <td>60+3</td>\n",
              "      <td>47+3</td>\n",
              "      <td>47+3</td>\n",
              "      <td>47+3</td>\n",
              "      <td>60+3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>€228.1M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>193080</td>\n",
              "      <td>De Gea</td>\n",
              "      <td>27</td>\n",
              "      <td>https://cdn.sofifa.org/players/4/19/193080.png</td>\n",
              "      <td>Spain</td>\n",
              "      <td>https://cdn.sofifa.org/flags/45.png</td>\n",
              "      <td>91</td>\n",
              "      <td>93</td>\n",
              "      <td>Manchester United</td>\n",
              "      <td>https://cdn.sofifa.org/teams/2/light/11.png</td>\n",
              "      <td>€72M</td>\n",
              "      <td>€260K</td>\n",
              "      <td>1471</td>\n",
              "      <td>Right</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Medium/ Medium</td>\n",
              "      <td>Lean</td>\n",
              "      <td>Yes</td>\n",
              "      <td>GK</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Jul 1, 2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020</td>\n",
              "      <td>6'4</td>\n",
              "      <td>168lbs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>€138.6M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>192985</td>\n",
              "      <td>K. De Bruyne</td>\n",
              "      <td>27</td>\n",
              "      <td>https://cdn.sofifa.org/players/4/19/192985.png</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>https://cdn.sofifa.org/flags/7.png</td>\n",
              "      <td>91</td>\n",
              "      <td>92</td>\n",
              "      <td>Manchester City</td>\n",
              "      <td>https://cdn.sofifa.org/teams/2/light/10.png</td>\n",
              "      <td>€102M</td>\n",
              "      <td>€355K</td>\n",
              "      <td>2281</td>\n",
              "      <td>Right</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>High/ High</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Yes</td>\n",
              "      <td>RCM</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Aug 30, 2015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>5'11</td>\n",
              "      <td>154lbs</td>\n",
              "      <td>82+3</td>\n",
              "      <td>82+3</td>\n",
              "      <td>82+3</td>\n",
              "      <td>87+3</td>\n",
              "      <td>87+3</td>\n",
              "      <td>87+3</td>\n",
              "      <td>87+3</td>\n",
              "      <td>87+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>88+3</td>\n",
              "      <td>...</td>\n",
              "      <td>73+3</td>\n",
              "      <td>66+3</td>\n",
              "      <td>66+3</td>\n",
              "      <td>66+3</td>\n",
              "      <td>73+3</td>\n",
              "      <td>93.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>€196.4M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      ID  ... GKReflexes  Release Clause\n",
              "0           0  158023  ...        8.0         €226.5M\n",
              "1           1   20801  ...       11.0         €127.1M\n",
              "2           2  190871  ...       11.0         €228.1M\n",
              "3           3  193080  ...       94.0         €138.6M\n",
              "4           4  192985  ...       13.0         €196.4M\n",
              "\n",
              "[5 rows x 89 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbKvNqWR_mjq",
        "outputId": "7f19b267-59a0-42b7-956c-848bbecf7ea3"
      },
      "source": [
        "new_tokens = set()\n",
        "for name, club in zip(fifa19_df.Name[:3000], fifa19_df.Club[:3000]):\n",
        "  \n",
        "  try:\n",
        "    new_tokens.update([x.lower().strip() for x in name.split()])\n",
        "    new_tokens.update([x.lower().strip() for x in club.split()])\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "list(new_tokens)[:20]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mariano',\n",
              " 'casillas',\n",
              " 'herrera',\n",
              " 'morales',\n",
              " 'hansen',\n",
              " 'mertens',\n",
              " 'alcácer',\n",
              " 'dúbravka',\n",
              " 'diedhiou',\n",
              " 'milan',\n",
              " 'lopes',\n",
              " 'malatyaspor',\n",
              " 'mierzejewski',\n",
              " 'toxeto',\n",
              " 'sinobo',\n",
              " 'khacheridi',\n",
              " 'hetemaj',\n",
              " 'rafa',\n",
              " 'i̇nan',\n",
              " 'rebrov']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSFAx8hX0vQh",
        "outputId": "ce8d0b67-d783-4932-d3f2-dd6c55301046"
      },
      "source": [
        "tokenizer.add_tokens(list(new_tokens))\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(34018, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVlETYF11LbB"
      },
      "source": [
        "We can proced doing the same thing with the tags. We will extract all the tags present in the tweets and count them. Then we will add to the tokenizer the ones that are most present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGO9B2JxY0ms"
      },
      "source": [
        "tags = {}\n",
        "re_tags = re.compile('[@#][\\w\\d_]+')\n",
        "for tweet in tweets:\n",
        "  for tag in re_tags.findall(tweet):\n",
        "    tag = tag.lower()\n",
        "    tags[tag] = tags.get(tag, 0) + 1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlKE7bAFeHf1"
      },
      "source": [
        "list_tags_to_add = []\n",
        "list_tags_to_remove = []\n",
        "\n",
        "for tag, count in tags.items():\n",
        "  if count >= 10:\n",
        "    list_tags_to_add.append(tag)\n",
        "  else:\n",
        "    list_tags_to_remove.append(tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgwcWnuDx4k-",
        "outputId": "2e831546-964f-45ca-f97d-adb522ef367d"
      },
      "source": [
        "list_tags_to_add += ['##fc']\n",
        "tokenizer.add_tokens(list_tags_to_add)\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(34376, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVazhlEPsnSe"
      },
      "source": [
        "Finally we will perform a simple cleaning of the tweets, removing websites and newlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP-Xxit235Fq"
      },
      "source": [
        "def clean(s):\n",
        "    s = re.sub('http[^ ]+', '', s) # remove websites\n",
        "    s = re.sub('\\n|( ){2,+}', '', s)\n",
        "    return s\n",
        "\n",
        "tweets = df.tweet_text.apply(clean).to_list()\n",
        "sentiment = df.sentiment.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6flymzy35DP",
        "outputId": "ad345781-fded-4298-fe6f-11a32cb8d1aa"
      },
      "source": [
        "for s in tweets[:10]:\n",
        "  print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@LichtsteinerSte @juventusfc Grazie di tutto,#SwissExpress,sono stati 7 anni indimenticabili fatti di vittorie,sconfitte (poche!),enormi gioie e tante incazzature in campo con gli arbitri.? Sono stati 7 anni da #MY7H.Mi mancherai.???\n",
            "Scusami @Cristiano, potresti dirci se oggi arrivi a Torino?Va bene pure un’ autocertificazione, tanto siamo in Italia... @juventusfc\n",
            "@NonEvoluto @PReina25 @MassMirabelli Max nelle cessioni è top.. negli acquisti può migliorare\n",
            "@PasquAmatoJ8 @MarioMandzukic9 @G_Higuain @juventusfc Tanti auguri Gonzalo\n",
            "Nonostante l'odio sportivo verso la @juventusfc, che grande colpo portare @Cristiano in @SerieA_TIM! Spero il @sscnapoli risponda a questo colpo!\n",
            "@EVUJ1897 @PauDybala_JR Thank you very mouch Vedic che scherzo per me sei unable sorella e gobba bianconera e fai parte Della famiglia @juventusfc\n",
            "@Luca_Cilli @Cristiano @juventusfc @tvdellosport Grazie Luca, gentilissimo!\n",
            "@georginajacaa @Cristiano @DoloresAveiro @juventusfcen Benvenuti nella casa di tutti noi juventini ! ? Siete una meraviglia ... un piacere ed un onore avervi fra noi ! ? #juve #family #CR7DAY #CR7JUVE Ancora benvenuto, mejor ! @Cristiano ??\n",
            "@PBPcalcio @gigiodonna1 Speriamo contunui cosi. Si potrà vendere a buon prezzo\n",
            "@MarioMandzukic9 grandissimo Marione!! Finale meritatissima!! Go!! ??\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu4qRTX6ejOg"
      },
      "source": [
        "# cleaned_tweets = []\n",
        "# re_tags = re.compile('[@#][\\w\\d_]+')\n",
        "# for tweet in tweets:\n",
        "#   for tag in re_tags.findall(tweet):\n",
        "    \n",
        "#     if tag in list_tags_to_remove:\n",
        "#       tweet = tweet.replace(tag, '')\n",
        "\n",
        "#   cleaned_tweets.append(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTuwfZQbfUi3",
        "outputId": "b45a7d81-6f58-4360-b226-e31e3c187fd7"
      },
      "source": [
        "tokenizer.tokenize(tweets[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@lichtsteinerste',\n",
              " '@juventus',\n",
              " 'fc',\n",
              " 'graz',\n",
              " 'ie',\n",
              " 'di',\n",
              " 'tutto',\n",
              " ',',\n",
              " '#',\n",
              " 'swiss',\n",
              " '##ex',\n",
              " '##press',\n",
              " ',',\n",
              " 'sono',\n",
              " 'stati',\n",
              " '7',\n",
              " 'anni',\n",
              " 'indimenti',\n",
              " '##cabili',\n",
              " 'fatti',\n",
              " 'di',\n",
              " 'vittorie',\n",
              " ',',\n",
              " 'sconfitte',\n",
              " '(',\n",
              " 'poche',\n",
              " '!',\n",
              " ')',\n",
              " ',',\n",
              " 'enormi',\n",
              " 'gioi',\n",
              " '##e',\n",
              " 'e',\n",
              " 'tante',\n",
              " 'inca',\n",
              " '##zza',\n",
              " '##ture',\n",
              " 'in',\n",
              " 'campo',\n",
              " 'con',\n",
              " 'gli',\n",
              " 'a',\n",
              " 'rb',\n",
              " 'it',\n",
              " '##r',\n",
              " 'i.',\n",
              " '?',\n",
              " 'sono',\n",
              " 'stati',\n",
              " '7',\n",
              " 'anni',\n",
              " 'da',\n",
              " '#my7h',\n",
              " '.',\n",
              " 'mi',\n",
              " 'manch',\n",
              " '##era',\n",
              " 'i.',\n",
              " '?',\n",
              " '?',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "6NebUg9pHYut",
        "outputId": "fe3d96ce-b9ca-4782-e652-b089d10dd227"
      },
      "source": [
        "it_bert_model.finetune(tweets, labels=sentiment, epochs=4, optimizer_parameters =  dict(lr=5e-5), num_tokens_per_class=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-ac95e50e70ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mit_bert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_parameters\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens_per_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/neuraltextgen/NeuralTextGenerator.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(self, sentences, labels, mask_percentage, epochs, batch_size, optimizer, optimizer_parameters, scheduler, scheduler_parameters, num_tokens_per_class)\u001b[0m\n\u001b[1;32m    346\u001b[0m             self.encoder = LabelEncoder(self.model, self.tokenizer, classes=classes,\n\u001b[1;32m    347\u001b[0m                                         num_tokens_per_class=num_tokens_per_class)\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mencoded_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# Retrieve tokenized sentences and attention masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/neuraltextgen/textprocessing.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, lines, labels)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mlabeled_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_special_tokens_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/neuraltextgen/textprocessing.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, lines)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Add '[CLS]' and '[SEP]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Construct attn. masks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Return pytorch tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2582\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m         )\n\u001b[1;32m   2586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0msub_text\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                         \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_on_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8c1IdI9HrGw"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 2,  \n",
        "              'batch_size': 2,\n",
        "              'avg_len':30,\n",
        "              'max_len':50,\n",
        "              # 'std_len' : 3,\n",
        "              'generation_method':'parallel',\n",
        "              'sample': True,\n",
        "              'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              'top_k': 100,\n",
        "              'seed_text': \"[POSITIVE-0] [POSITIVE-1] [POSITIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnCnuQ2_6NkQ"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 2,  \n",
        "              'batch_size': 2,\n",
        "              'avg_len':30,\n",
        "              'max_len':50,\n",
        "              # 'std_len' : 3,\n",
        "              'generation_method':'attention',\n",
        "              'sample': True,\n",
        "              'burnin': 250,\n",
        "              'max_iter': 300,\n",
        "              'top_k': 100,\n",
        "              'seed_text': \"[POSITIVE-0] [POSITIVE-1] [POSITIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61vletr76Nhe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "952q0hJ86Ne6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zce8zS7s6NcD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Da9zUHR6NZf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdzm_tdM6NWg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnTEg6jH6NM0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VboOo1wROlNx",
        "outputId": "793aae32-c183-444c-a66c-9541c593013f"
      },
      "source": [
        "sents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ma faccia di uno dei unici al..', '##gior']"
            ]
          },
          "execution_count": 190,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leWUP0uqLYov",
        "outputId": "0f337a57-8b1d-4073-d4e1-76b0f1c9a10a"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "              'seed_text': \"[POSITIVE-0] [POSITIVE-1] [POSITIVE-2]  Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo se un anno tu traccii lo ci vuol dire sempre un godimento e una solo cristian n e. che ti fara n oi bene!!!\n",
            "ro naldo..... complimenti per il # calcioapostotan e..... sei arrivata solo oggi e poco granche..???\n",
            "ro naldo @sscnapoli @ mountini76 oggi sei un uomo ridicolo, pieno di sputtti i. e alquanto esagerato... buon cotu!??\n",
            "ro naldo @realvarriale @juventusfc @ cristian o forza lo stai al meglio??? dirigi la roma e ti ricordi sempre n emmen o calciatore interist o.??\n",
            "ro naldo jr @ mo pita 2 @realvarriale _ bonucci @ cristian jr @juventusfc @juventusfc graz itte pure ars a... ma e un ciclo altr e..\n",
            "ro naldo non e educato e le cose lontana da m scr o... non sc ud a nessuno e giov tanno..?????\n",
            "ro naldo @ rolli verde @juventusfc @ cristian o l da grande sei che partita mancata avevamo, del genere sara v ivo accorciato oraesploervabil e.\n",
            "ro naldo tifoso del chelsea, sempre piu orgoglio nel nostro cuore e fran lia!!! solo dei grandi campioni del calcio! vinciamo lui!!!\n",
            "ro naldo @ mazzolenna @ andrea rc ocellaroma complimenti per la ter a.... de tutto cio che ci serve in club. fidati di me\n",
            "ro naldo. e basta un gol ( si non basta un secondo ).. eravamo tutti campioni per n oi e solo da n oi e da n il gol\n",
            "CPU times: user 5.42 s, sys: 14 ms, total: 5.44 s\n",
            "Wall time: 5.46 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8F6fYxJLdA7",
        "outputId": "ca297c07-6761-4ce3-e264-3904d2a33ea8"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo @ bidi @juventusfc sei solo una feccia che procura un soldo e un spog lia o per tutta la societa!!....\n",
            "ro naldo, o alla lontana, parigi @inter sempre a te ( tutto il mio cuore solo per la nostra squadra ancora in ), per il mio g lais\n",
            "ro naldo napoli devi tornare a napoli e curare la tua piaga di n ng ino... # napolicalcialalve!eeeeee!!\n",
            "ro naldo vieni fin dal mondiale insigne, purtroppo ci dobbiamo creder e. no, mai visto p oi, io mi vergogno di sc o. @douglascosta???\n",
            "ro naldo purtroppo se de vv ero cosi gira un pezzo, ma stasera e con quella di @ officialra dja insieme ad alde til e fuori!\n",
            "ro naldo ora tu vattene da dove vuoi stare, sempre, resta a casa mia, altrimenti vai via tutto il sol o. tu fai l'infermin e.\n",
            "ro naldo @juventusfc non incatton taz e... bensi fate parte di una squadra, lo sai che l'avrebbe comprato!!.. comunque\n",
            "ro naldo si porta il reeido golico alla mot @mrancelotti a per la partita vinta dal milan, la secchia ne fa un entrar e.\n",
            "ro naldo @ cristian o1971 @ officialra dja @ spalletti _ 16 bravo ma eh no, questi sant i.. ti pas la juve\n",
            "ro naldo @ mag lia @sscnapoli @ cristian o official ma giochiamo in 25 mondiali di calcio \" sulla @juventusfc \" e poi nei mondiali della juventini o..\n",
            "CPU times: user 7.1 s, sys: 14.1 ms, total: 7.11 s\n",
            "Wall time: 7.13 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa99Ed4kqcSD",
        "outputId": "c3f28237-dd78-426f-802b-2fa28a07edd4"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.2,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo @juventusfc @ francesc cardi!! piace la merda!??!?? un professionista che va a fondo!?? un sorriso\n",
            "ro naldo _ @kmbappe @juventusfc @ daniele _ pallotta @juventusfc riprenditi la mag lia e con la famig lia... buona ciro??\n",
            "ro naldo o @ clav @douglascosta a ti vedo e non penso a te nulla stai zitto tu @ cristian o ridi e riattacca e. ti voglio bene\n",
            "ro naldo @juventusfc pastore dybala vi auguro cari tifosi vincete il mondiale piu brutto del mondo!!!! una felice vita sempr...\n",
            "ro naldo @ mario sai chi veramente sai il nome della mia faccia di prima ero una persona normale come mi sono comportato per loro sempre del tutto ridicolo i.\n",
            "ro naldo e. ho visto un incubo @ nascondidocumentiment i. sei un schifoso! figlio di puttana!!!!!???!?\n",
            "ro naldo @ pau dybala _ jr @ cristian o i cori piu immol i. razzisti ci indigna no ne ad espol e. pessimo au guri\n",
            "ro naldo sulla cag lia rna abbiamo detto che non ti r oi... graz ie, condi guri e....!??\n",
            "ro naldo sicuramente, pe rc he in un'altra operazione di campionato ci mancherebbe quanto fa l ” cenerenti ”, non ci vuole neanch oti\n",
            "ro naldo @ leo1963 @juventusfc @ @joaome17 @acmilan sei l'unico portiere che voglio e giocar e....... ina o. #\n",
            "CPU times: user 7.06 s, sys: 24.9 ms, total: 7.09 s\n",
            "Wall time: 7.12 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP-SjKHmyJyz",
        "outputId": "c035257f-2328-45ac-f773-9c6f4a12fde3"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.5,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo @juventusfc vergogna! se nun si impegna bene per via dell'amichevolezza un imbecill a.... sei diventato un vero pietruguardier a.\n",
            "ro naldo keita @g_higuain @ spry @ napoleon nessuno fara sentire mai viva la intera famig lia! piu problem e.! gli interisti sono delusi\n",
            "ro naldo juventu che ha aspettato la bella partita e non ha salvato l ultimo dall ita mia, ma terra di cheyss i. poco prima del mondiale calcio\n",
            "ro naldo @sscnapoli quanto a roma e non vincere neanche la champions, non andare in giro t i... si, averti alla roma sarebbe una cosa mostruosi!\n",
            "ro naldo @juventusfc @ gideus lavoriamo pallineve e la sua voce ci fa sentire nel cuore di fer e....?????\n",
            "ro naldo che, da atleta del nostro passo anche agli idi i.? quel me rc simo @ cristian o @skysport @ cristian o @ cristian o??\n",
            "ro naldo @ cristian o vinciamo il miglior pallone del mondo!!! # massjuve @ cristian @ alisson lo potevi rovinare! sei un paol o.\n",
            "ro naldo @g_higuain @ termi @juventusfc sono tutti yec, figure di poco spessore, e nessuno stupido a fare ecki tecnico e vergognoso # ro naldo @g_higuain\n",
            "ro naldo @sscnapoli @ lucari _ 5 mi hanno intimato di andar via cosi chiedo se vorrebbe far capuano pure ve rc i un bravo @ cristian i.\n",
            "ro naldo di mag lia semplice nessuna feccia e tutto li che va fuori di torno dal punto di vista sono i giocatori in campo nello stadio e gli elfici\n",
            "CPU times: user 7.22 s, sys: 14 ms, total: 7.23 s\n",
            "Wall time: 7.26 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMincstXyJwh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTGmDZkZyJuK",
        "outputId": "1c25fce1-51b9-4f16-da82-a3b4593fe958"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.5,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 1000,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo ii @ sambe pell er? bravo @ officialra dja?????????????????\n",
            "ro naldo sempre il migliore!!??? squadra di merda come ci si vede!??? @douglascosta ed!??? ti amo???\n",
            "ro naldo @mariomandzukic9 cosi fiero di te in campo e nelle maltrom o. ma che schifo fra n oi n oi??? napoli ti amo!??\n",
            "ro naldo @ cristian o comunque che cazzana hai? non dormi mai pe rc he? non ti svegli mai pe rc he??????\n",
            "ro naldo invidia per la tua merda allegri tutta quanto il mio per bena tro cirio, cio non e possibile! sei il migliore, il piu forte!\n",
            "ro naldo @ cristian o @realvarriale @ cristian o28 @realvarriale @ f akan olympique @ officialra dja ma ha risposto???????\n",
            "ro naldo e un giocatore del napoli ma sicuramente ti manca anche te da un anno ora!. una grande famig lia. sei un grande tit o..\n",
            "ro naldo ma pe rc he ho con @officialallegri al tuo fianco il nuovo mondo ti soccorranno e ti trovera sempre????????\n",
            "ro naldo @ cristian o questa e stata la prima stagione di tutte le eta a esprimere la loro nuova inclinazione a fare quello che! ti amo???\n",
            "ro naldo @ cristian o tutti insieme in campo?? bravo? piu che nel cuore nei cuori di molti dei giocatori piu forti e di un vero evento incredibile.\n",
            "CPU times: user 19.5 s, sys: 50.1 ms, total: 19.5 s\n",
            "Wall time: 19.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM1UeOLA2cIn"
      },
      "source": [
        "ronaldo @cristiano comunque che cazzana hai? non dormi mai perche? non ti svegli mai perche??????\n",
        "ronaldo @movaro_jr siamo tutti pieni di professionalita e fantasia, ma ora e il momento di scegliere un altro giocatore, prima di redimere questa partita\n",
        "ronaldo ahahahahahahedeem a....... merda..... giornalista vergognati\n",
        "ronaldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\n",
        "ronaldo..... sempre calmo......... sempre calmo............"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZcZYjxqyJrp",
        "outputId": "6d05d941-9c7b-4049-cf4a-ff8903226a02"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.5,\n",
        "              'sample': True,\n",
        "              'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo anta @ officialra dja torna a torino e ti rived alm iamo.... un mondiale come n ente??\n",
            "ro naldo @juventusfc mi hai fatto risentire anche per questo, soprattutto ora che sei un tifatt isco, di sicuro fa bene al cuor a.\n",
            "ro naldo napoli non si diverte neanche a prendere in giro i nostri n oi!!!!!??????? @ cristian o\n",
            "ro naldo @juventusfc @ fa reina 25 torna a casa, si che uomo sei?? ho dimenticato di averti nel cuore???? graz ie?\n",
            "ro naldo ahahahahahahedeem a....... merd a..... giorna lis o vergognati\n",
            "ro naldo me lo devi dare 10, 000 euro per @ p oi re cristian o, io sono da vv ero a milano e ti as pett endo\n",
            "ro naldo fedex non e una cosa da calcio vile!! sei l'ennesimo dei peggiori tifosi interisti di n oi!\n",
            "ro naldo @juventusfc @ cirimo83 @ forzanapoli hai dato le spalle ai me rc ate, soprattutto per l espulsione mancata??\n",
            "ro naldo ma tu sei un campion o.??? sappi che chi non e interista, e un campion o...?????\n",
            "ro naldo @juventusfc @sscnapoli @juventusfc @ d _ 16 se vi accontentate di fare il tifo, ammesso che tu sia il nostro tiratore????\n",
            "CPU times: user 9.87 s, sys: 16 ms, total: 9.89 s\n",
            "Wall time: 9.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skZExkjmyJoq",
        "outputId": "9bede52f-4378-4c17-c467-e5c2f23af4c8"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.5,\n",
        "              'sample': True,\n",
        "              'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] [NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] [NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] [NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo @ cm24 @juventusfc per me e che ha fatto un po ’ incazzare la societa e i poveri imbecilli, ma non e che gli piacerebbe proprio obbedire\n",
            "ro naldo e'possibile che uno dei giornalaiovisti, come me, non abbia fatto nulla? no no, queste sono delle merde non si fa!\n",
            "ro naldo ma tu sei una mondial a.. kalidou kalidou resta con me e non andare via! kalidou, ti aveccompagnero per sempre!\n",
            "ro naldo tifo per te, non ti rosicare, vai a dimagrire, non lo so fare???????????\n",
            "ro naldo neanche lo posso dire, campione!!! avete giocato benissimo!!! che schifo!!! vergognoso!!!!! avete vinto!!\n",
            "ro naldo @ luisconquentino @juventusfc @ official lis ia complimenti inchetta schivetti il futuro!!! convoca sempre @ cristian o!\n",
            "ro naldo non l'avrebbe presa se non la restituit a. a volte n oi parlano dei funerali del povero uomo, che si fa spesso infastidire n oi\n",
            "ro naldo @ movaro _ jr siamo tutti pieni di professionalita e fantasia, ma ora e il momento di scegliere un altro giocatore, prima di redimere questa partita\n",
            "ro naldo @juventusfc @ cristian o... uno dei piu forti al mondo c alm i ad una tecnic e. ipocr a...!!!!!\n",
            "ro naldo @juventusfc @sscnapoli @ bonucci _ leo19 sei un grande fuori res #worldcup e sei vergognoso anche per gli interi club e i tifosi!!!!!!\n",
            "CPU times: user 10.7 s, sys: 13.1 ms, total: 10.7 s\n",
            "Wall time: 10.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaAAexhL0FQ6",
        "outputId": "fcc31227-e70f-4cb5-a445-7a2bbce3ccca"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'init_mask_prob':0.7,\n",
        "              'sample': True,\n",
        "              'burnin': 450,\n",
        "              'max_iter': 500,\n",
        "              'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] [NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo @sscnapoli @ cristian o @ reddefaoooooooo la merde in ita lia mo sta facendo un grosso sbaglio! # reddejuve\n",
            "ro naldo ma non lo romperemo mai! non si puo mai rompere la nostracourita squadra di merda di legami, ladri e ninja! non lo avrebbe fatto nessun altro\n",
            "ro naldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\n",
            "ro naldo @juventusfc forza campione! non n oi dire nulla, e che la maggior parte delle parti non hanno nulla in comune con la juve continua cosi, assolutamente no!\n",
            "ro naldo @juventusfc chiunque parli di tuttle non e razzista e non solo n oi pu ere un video! fate una foto, e questo invece non pu ere tuttle!\n",
            "ro naldo..... sempre calm o......... sempre calm o............\n",
            "ro naldo non te lo vog lia per niente.... per me non ced ivo e di prim o. e assolut a. per me non fa differenza\n",
            "ro naldo purtroppo oggi, a differenza di ieri con # klys, si gioca sempre una grande partita, ed e una grande partita senza pari, infatti ha fiutato\n",
            "ro naldo @ cristian o @ lor _ insigne complimenti i giocatori a gennaio e a luglio sono fulminati per la cessione della roma all'inter......\n",
            "ro naldo schifo di societa sei proprio un brut o. no sei peggio di loro..... vog lia mo che sei peggio di loro....\n",
            "CPU times: user 10.5 s, sys: 34.1 ms, total: 10.6 s\n",
            "Wall time: 10.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hydXVUB7djmv",
        "outputId": "b62766ee-bd75-4b66-d75c-7d7a4bc42a24"
      },
      "source": [
        "x = [\n",
        "     \"ro naldo sei un dio tutto cult o...????? forza unica, fai sempre la parte di sor e.... forza belgio\",\n",
        "\"ro naldo??????????????...... sei sempre nei nostri cuori i...?\",\n",
        "\"ro naldo... siamo felicissimi per te e franja sei un grande uomo ma resterai sempre napoli una grande icona sei tutto il nostro pensiero\",\n",
        "\"ro naldo _ @ ildoco1 @ kk76 sei grande e tant o.!!! sei un grande calciatore e sei un grande uomo!\",\n",
        "\"ro naldo grande noi, sei grande, un grande cuor e. noi ti amiamo???????????????\",\n",
        "\"ro naldo........... le lacrime mi stanno rendendo grand i. sempre di piu pipite??? mi sei mancato\",\n",
        "\"ro naldo e la scarpa dell'uomo paulo lauro e un grande giocatore, il piu forte della storia ma anche un dejouverabilissimo @dimarzio\",\n",
        "\"ro naldo tu sei stato uno di noi, sei un gran partit o. sei stato un grande partit o. sarai sempre azi o.... @juventus fc\",\n",
        "\"ronaldo tante complimenti per per il tuo bellissimo debutto, dopo aver visto il tuo punto forza e auguri @ _ / juventusfc # juventusfc # juventusfc?\",\n",
        "\"ronaldo invece ( quasi ) sono bene prima a ritorno al real un 17!????.. complimenti ma sono ben qui vicini, prossimi al gioco!\",\n",
        "]\n",
        "print('[POSITIVE] Ronaldo:')\n",
        "for s in x:\n",
        "  print(s)\n",
        "\n",
        "print('\\n\\n')\n",
        "x = [\n",
        "        \"ronaldo @cristiano comunque che cazzana hai? non dormi mai perche? non ti svegli mai perche??????\\n\",\n",
        "        \"ronaldo @movaro_jr siamo tutti pieni di professionalita e fantasia, ma ora e il momento di scegliere un altro giocatore, prima di redimere questa partita\\n\",\n",
        "\t\"ro naldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\\n\",\n",
        "        \"ronaldo ahahahahahahedeem a....... merda..... giornalista vergognati\\n\",\n",
        "        \"ronaldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\\n\",\n",
        "        \"ronaldo..... sempre calmo......... sempre calmo............\\n\",\n",
        "     \"ro naldo e ’ un idiot o. la grande partita dell ’ anno.. vuol dire che puoi anche vincer e. sei una grande person a... ma graz ie a te, enario\\n\",\n",
        "\"ro naldo @ interfrancy @juventus fc..... complimenti per l'acquisto..... complimenti a un grande giocatore!!!!! per me non e niente!\\n\",\n",
        "\"ro naldo io non ripugn o. lui e ridicolo e una merd e... noi non lo vogliamo come noi, dopo quasi un anno, non e piu uno “ zingaro ”??\\n\",\n",
        "\"ro naldo @ mijoro @ # higuain @ ma rc antino @ fn1 e un pe rc he tifoseria # 1ajuve # 1 # 1juve\\n\",\n",
        "      ]\n",
        "print('[NEGATIVE] Ronaldo:')\n",
        "for s in x:\n",
        "  print(s, end='')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[POSITIVE] Ronaldo:\n",
            "ro naldo sei un dio tutto cult o...????? forza unica, fai sempre la parte di sor e.... forza belgio\n",
            "ro naldo??????????????...... sei sempre nei nostri cuori i...?\n",
            "ro naldo... siamo felicissimi per te e franja sei un grande uomo ma resterai sempre napoli una grande icona sei tutto il nostro pensiero\n",
            "ro naldo _ @ ildoco1 @ kk76 sei grande e tant o.!!! sei un grande calciatore e sei un grande uomo!\n",
            "ro naldo grande noi, sei grande, un grande cuor e. noi ti amiamo???????????????\n",
            "ro naldo........... le lacrime mi stanno rendendo grand i. sempre di piu pipite??? mi sei mancato\n",
            "ro naldo e la scarpa dell'uomo paulo lauro e un grande giocatore, il piu forte della storia ma anche un dejouverabilissimo @dimarzio\n",
            "ro naldo tu sei stato uno di noi, sei un gran partit o. sei stato un grande partit o. sarai sempre azi o.... @juventus fc\n",
            "ronaldo tante complimenti per per il tuo bellissimo debutto, dopo aver visto il tuo punto forza e auguri @ _ / juventusfc # juventusfc # juventusfc?\n",
            "ronaldo invece ( quasi ) sono bene prima a ritorno al real un 17!????.. complimenti ma sono ben qui vicini, prossimi al gioco!\n",
            "\n",
            "\n",
            "\n",
            "[NEGATIVE] Ronaldo:\n",
            "ronaldo @cristiano comunque che cazzana hai? non dormi mai perche? non ti svegli mai perche??????\n",
            "ronaldo @movaro_jr siamo tutti pieni di professionalita e fantasia, ma ora e il momento di scegliere un altro giocatore, prima di redimere questa partita\n",
            "ro naldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\n",
            "ronaldo ahahahahahahedeem a....... merda..... giornalista vergognati\n",
            "ronaldo??? molto bene? molto bene??? non si vince mai con sportivita e fiducia non ti preoccupare hai dimostrato di non poter faticare a nulla\n",
            "ronaldo..... sempre calmo......... sempre calmo............\n",
            "ro naldo e ’ un idiot o. la grande partita dell ’ anno.. vuol dire che puoi anche vincer e. sei una grande person a... ma graz ie a te, enario\n",
            "ro naldo @ interfrancy @juventus fc..... complimenti per l'acquisto..... complimenti a un grande giocatore!!!!! per me non e niente!\n",
            "ro naldo io non ripugn o. lui e ridicolo e una merd e... noi non lo vogliamo come noi, dopo quasi un anno, non e piu uno “ zingaro ”??\n",
            "ro naldo @ mijoro @ # higuain @ ma rc antino @ fn1 e un pe rc he tifoseria # 1ajuve # 1 # 1juve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo-G69KeL3I3",
        "outputId": "09e30550-de9b-42d5-e300-37e1e6366e55"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              'max_iter': 400,\n",
        "              'seed_text': \"[POSITIVE-0] [POSITIVE-1] [POSITIVE-2]  Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo lis simo @ milan182 @ k koulibaly 26 purtroppo non ho detto proprio ora il messaggio ma gia sbag lia o rassett rc anta\n",
            "ro naldo si, resta in basso # merisi! alla tua fune. altr a. sei il s alm ueno della giorn ta! altr a.\n",
            "ro naldo @ @g_higuain @g_higuain @juventusfc sei un augurio a tutti buon anno! un grande campione!!!!! e vero guardare la partita!????\n",
            "ro naldo @ cristian o @g_higuain era solo per quanto lo scorso anno complimenti alla roma sempre pe rc he vincete!!! festeggiamo sempre la nostra roma!!\n",
            "ro naldo, per n paz @g_higuain uno come @ pau dybala _ jr e un ano rc o come vv o, v oti i serve ar rb.???\n",
            "ro naldo!!!!! @ blackglass @ k o. 21 graz ie v roa e re contr o...!!!!!!\n",
            "ro naldo gianluigi oooooooooooooooooooooooooooooooo????????????\n",
            "ro naldo!!!???????...!!! fortuna ie a te!??????????\n",
            "ro naldo sei uomo in ogni t a. avere questa vergogna nel tuo cuore e il tut ito, per incassarlo con questa fin p. a del tut ito\n",
            "ro naldo quella notte ha fatto peggio di questo giocatore giadin o... che ce ne sia inte ito imin o... ma no di questa mag lia!\n",
            "CPU times: user 7.89 s, sys: 19 ms, total: 7.91 s\n",
            "Wall time: 7.94 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmZr6GMrgRKF",
        "outputId": "9453a7b3-a857-40b0-fde8-56d46c7e3f62"
      },
      "source": [
        "%%time\n",
        "\n",
        "parameters = {'n_sentences': 10,  \n",
        "              'batch_size': 10,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "             'seed_text': \"[NEGATIVE-0] [NEGATIVE-1] [NEGATIVE-2] Ronaldo \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ro naldo la qualificazione di oggi per ljuveb a r eder e con ng..... ma con tutto il r eder o, forse non hai il buon cuore\n",
            "ro naldo tranquillo @ paul pogba, non ci vedo piu a vi ng ere.....................\n",
            "ro naldo o graz ie!! mi raccomando, sei un gran partit a... ma come @juventusfc @mariomandzukic9 a torino, si riprenderanno presto!!!!!!!\n",
            "ro naldo??????????? gli stipendi ai giovani ancora un giorno, un anno per n oi ecc. per il resto di un grande anno\n",
            "ro naldo scusa tanto e non per @ rodrivarrl e. gia ora ho sempre nel cuore @ cristian o e le compagne oggi soprattutto, napomarro!!!!\n",
            "ro naldo grande talento in @juventusfc il piccolino della ferrari vale poco in cos a. peccato, non si vende la mag lia per insultare un giocatore che non ha nulla per n oi\n",
            "ro naldo @ realtosu griezmann82 una minchiata favor e.......eeeeeeeeeeeeeeeeee......\n",
            "ro naldo non sottovalutarti troppo la professionalita, soprattutto il # napol o. questo vos o. o sicuramente ti sosterra uno dei propri allenatori e meglio se una fascicola zia\n",
            "ro naldo @ cristian o le dico che fino alla serata sarebbe sceso in campo @ cristian o o comunque meglio che lei abbia un finale svitato!!??????\n",
            "ro naldo @g_higuain @ cristian o @ alisson becker paus jr e sc ivo med o... mi dispiace per tutti, anche per @ cristian o per la differenz o...\n",
            "CPU times: user 8.27 s, sys: 10 ms, total: 8.28 s\n",
            "Wall time: 8.28 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNnBgT82jkjy",
        "outputId": "2f40eb4a-ad30-4818-ead9-f4c5e9c2dd9c"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':30,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 3,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 400,\n",
        "             'seed_text': \"Ronaldo [POSITIVE-0] [POSITIVE-1] [POSITIVE-2] [POSITIVE-0] [POSITIVE-1] [POSITIVE-2]\",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "for s in sents:\n",
        "    print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ronaldo tante complimenti per per il tuo bellissimo debutto, dopo aver visto il tuo punto forza e auguri @ _ / juventusfc # juventusfc # juventusfc?\n",
            "ronaldo invece ( quasi ) sono bene prima a ritorno al real un 17!????.. complimenti ma sono ben qui vicini, prossimi al gioco!\n",
            "ronaldo e sempre sempre con moe?! # 266????????? per me?????????\n",
            "CPU times: user 22.4 s, sys: 52.5 ms, total: 22.5 s\n",
            "Wall time: 22.4 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uqfw2AX6hvOQ",
        "outputId": "1670f705-10c0-4a08-db07-5b9cb95eddf1"
      },
      "source": [
        "np.unique(df.sentiment, return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['MIXED', 'NEGATIVE', 'POSITIVE'], dtype=object),\n",
              " array([ 19, 209, 772]))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWAsvZGdiaOH"
      },
      "source": [
        "x = [\n",
        "     \"ro naldo sei un dio tutto cult o...????? forza unica, fai sempre la parte di sor e.... forza belgio\",\n",
        "\"ro naldo??????????????...... sei sempre nei nostri cuori i...?\",\n",
        "\"ro naldo... siamo felicissimi per te e franja sei un grande uomo ma resterai sempre napoli una grande icona sei tutto il nostro pensiero\",\n",
        "\"ro naldo _ @ ildoco1 @ kk76 sei grande e tant o.!!! sei un grande calciatore e sei un grande uomo!\",\n",
        "\"ro naldo grande noi, sei grande, un grande cuor e. noi ti amiamo???????????????\",\n",
        "\"ro naldo........... le lacrime mi stanno rendendo grand i. sempre di piu pipite??? mi sei mancato\",\n",
        "\"ro naldo e la scarpa dell'uomo paulo lauro e un grande giocatore, il piu forte della storia ma anche un dejouverabilissimo @dimarzio\",\n",
        "\"ro naldo tu sei stato uno di noi, sei un gran partit o. sei stato un grande partit o. sarai sempre azi o.... @juventus fc\",\n",
        "\"ronaldo tante complimenti per per il tuo bellissimo debutto, dopo aver visto il tuo punto forza e auguri @ _ / juventusfc # juventusfc # juventusfc?\",\n",
        "\"ronaldo invece ( quasi ) sono bene prima a ritorno al real un 17!????.. complimenti ma sono ben qui vicini, prossimi al gioco!\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reItuMMZE_vL"
      },
      "source": [
        "# Italian reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khYdu1UxFA8m",
        "outputId": "41695b93-905a-4690-9bae-fba2716122a9"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# os.chdir(\"/content/neuraltextgen/\")\n",
        "# from NeuralTextGenerator import BertTextGenerator, FormatTokenizer\n",
        "\n",
        "\n",
        "it_bert_model = BertTextGenerator(\"dbmdz/bert-base-italian-uncased\")\n",
        "tokenizer = it_bert_model.tokenizer\n",
        "model = it_bert_model.model\n",
        "device = it_bert_model.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Cld__2FBXq"
      },
      "source": [
        "df = pd.read_csv('development.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Izgi4VN9FWZ-",
        "outputId": "d51fc1d8-f888-435a-b8ae-5fe69f9cad6f"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Non è l'hotel più lussuoso in cui abbia mai so...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Siamo stati qui per 1 notte prima della nostra...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hotel è ben posizionato per visitare Torino. A...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All'arrivo la cordialità e disponibilità dello...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbiamo soggiornato per due notti alla fine de...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28749</th>\n",
              "      <td>L'hotel è vecchio ma caratteristico e devo dir...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28750</th>\n",
              "      <td>Per essere un 4 stelle L la camera era un pò s...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28751</th>\n",
              "      <td>Io e mia mamma (di età compresa tra 23 e 62) s...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28752</th>\n",
              "      <td>Ci siamo sentiti accolti e coccolati fin dall'...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28753</th>\n",
              "      <td>Soggiorno fantastico in una posizione fantasti...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28754 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text class\n",
              "0      Non è l'hotel più lussuoso in cui abbia mai so...   pos\n",
              "1      Siamo stati qui per 1 notte prima della nostra...   pos\n",
              "2      Hotel è ben posizionato per visitare Torino. A...   pos\n",
              "3      All'arrivo la cordialità e disponibilità dello...   pos\n",
              "4      Abbiamo soggiornato per due notti alla fine de...   pos\n",
              "...                                                  ...   ...\n",
              "28749  L'hotel è vecchio ma caratteristico e devo dir...   neg\n",
              "28750  Per essere un 4 stelle L la camera era un pò s...   pos\n",
              "28751  Io e mia mamma (di età compresa tra 23 e 62) s...   pos\n",
              "28752  Ci siamo sentiti accolti e coccolati fin dall'...   pos\n",
              "28753  Soggiorno fantastico in una posizione fantasti...   pos\n",
              "\n",
              "[28754 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hysGAFFUF3oU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R21WN8UIGE9K",
        "outputId": "e317adad-fc2c-4333-9e89-14a3eb76d518"
      },
      "source": [
        "for i in range(20):\n",
        "  print(i)\n",
        "  print(df.iloc[i].text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Non è l'hotel più lussuoso in cui abbia mai soggiornato, ma l'esperienza complessiva è di prima classe. Direttamente dall'accoglienza iniziale alla reception da Linda o Roberta per il servizio cordiale e efficiente da Luigis (1) e il suo team nel ristorante a Luigis (2) nel Bar sulla terrazza dell'hotel è, a mio avviso eccezionale. Piccolo (60 camere) e cordiale con un fedelissimi Client, molti dei quali visita ogni anno parla da sé. Tutte sapientemente gestito sotto l'occhio vigile di Mario, sono una grande squadra.\n",
            "\n",
            "L'hotel si trova sulla cima di una scogliera fuori il porto principale di Ischia. Facile da raggiungere a piedi verso il basso, ma impegnativa torna su per la collina. Ma ci sono molti autobus e i taxi - anche se caro a €15 fiera fisso per un 10 minuti di macchina (se che).  Cerca la scorciatoia fuori dei giardini piuttosto che un approccio principale e seguendo la strada principale.\n",
            "\n",
            "Ci sono due piscine, ma ci siamo limitati alla piscina inferiore più piccola - v acqua calda, set in giardini ben curati, si affaccia sulla baia sottostante. E credo che la cosa che - niente asciugamani sui lettini prima colazione !! Un sacco di spazio quando abbiamo soggiornato (metà giugno), ma non so cosa può essere come in agosto.\n",
            "\n",
            "Ci siamo andati per l'opzione mezza pensione, e abbiamo mangiato la sera nel ristorante con terrazza che guarda il Med blu e le montagne dell'Italia continentale in sottofondo. Il cibo servito era tanto vario e molto buono, con un servizio eccellente da la squadra di Luigi. Abbiamo mangiato fuori una notte giù al porto che ha fatto un bel cambiamento, e avrebbe potuto avere il pranzo come una sostituzione.\n",
            "\n",
            "Un aspetto stravagante dell'hotel era che ho firmato per cibo e bevande senza mai vedere la somma totale che mi è stata la firma per. Tuttavia, Chi ha tratto che ci potesse non essere un problema in quanto c'erano così tanti clienti affezionati ed abbastanza sicuro, la mia stima del conto finale era decisamente superiore a quello che è in realtà !\n",
            "\n",
            "Devo dire che la camera che avevamo visualizzata una delle più belle vista mare che ho sperimentato in alcune notti in hotel. La camera in sé era di buone dimensioni con bagno adiacente (solo doccia, che non era un problema per noi).  Due camere 309/310 sono state ritirate dall'edificio principale su per la collina leggermente che era il motivo per cui abbiamo avuto le vedute migliori e posizione tranquilla. Entrambi hanno la loro propria sun terraces ciò dovrebbe essere preferito.\n",
            "\n",
            "Non è un hotel, direi che per famiglie o per coloro con problemi di mobilità, in quanto è scolpita con gusto e in giù per la collina. L'architetto ha specialità stessa completamente utilizzato le caratteristiche fisiche dell'isola per migliorare la struttura.\n",
            "\n",
            "Ho anche utilizzato per nuotare dalla spiaggia nella splendida sul mare cristallino, che viene occupato con le navi ormeggiate durante i fine settimana. Difficile anche per entrare e uscire dal mare elegantemente senza le scarpe in plastica di una sorta come la spiaggia è pavimentazione e ghiaia, quindi prendere alcune se si prevede il coraggio di affrontare i 120 gradini per approfittare del mare. Ne vale la pena a mio avviso, ma non per i deboli di cuore.\n",
            "\n",
            "Parlando di cui ho noleggiato una bicicletta per contribuire a mantenere l'aumento di peso di pasta presso la baia, e la bicicletta sull'isola è stata un'esperienza, se si poteva andare fuori dell'hotel fino al zig zag approccio senza che si verifichi una spappola !!\n",
            "\n",
            "A mio parere un esperienza complessiva eccezionale dell'hotel, che ho trovato le recensioni negative difficile da trovare. Il personale era buona e trattati con ogni esigenza con facilità cordiale ed efficiente. Una posizione ideale per un riposo e relax di una settimana.\n",
            "\n",
            "Da il modo - non lasciate che nessuno parla con voi a prendere il servizio di autobus circolare per visitare l'isola. Prendete una gita organizzata a meno che non si sono contenuti permanente con maggior parte della strada (2 ore) appeso su un treno in grado di vedere fuori della finestra per tutti gli altri gli scommettitori facendo lo stesso. Gli autobus sono piccole e ottenere molto affollato.\n",
            "\n",
            "Anche di connessione internet Wi-Fi gratuita in tutto l'hotel, che è una cosa rara di questi tempi.\n",
            "\n",
            "Buone vacanze!!\n",
            "1\n",
            "Siamo stati qui per 1 notte prima della nostra sinistra della crociera da Venezia. Il personale era molto gentile e disponibile. Le camere erano pulite e confortevoli e la colazione era eccellente. Ci hanno anche aiutato nel trasporto privato findng direttamente al terminal crociere a un prezzo molto buono.\n",
            "2\n",
            "Hotel è ben posizionato per visitare Torino. A circa 100m dalla fermata dell'autobus per l'aeroporto e la stazione ferroviaria. Inoltre, tutte le principali aree di interesse turistico sono raggiungibili a piedi dall'hotel. La camera era ben arredata in uno stile moderno ma elegante. Buona scelta di canali televisivi in inglese. Selezione della colazione era buono con alta qualità.\n",
            "3\n",
            "All'arrivo la cordialità e disponibilità dello staff La qualità delle camere dell'ala nuova,molto moderne e ben arredate. La colazione ottima Ritornerò. Ottimo per viaggi di lavoro o per un soggiorno per la visita della città. Raccomandato!\n",
            "4\n",
            "Abbiamo soggiornato per due notti alla fine della nostra crociera. Personale molto cortese. Siamo stati in grado di lasciare i bagagli al mattino presto e iniziare la nostra visita immediatamente. Bellissimo hotel e camera elegante. Abbiamo mangiato nel ristorante che è stato superlativo. Consiglio vivamente questo bellissimo hotel - ottima posizione per tutti i mezzi di trasporto - Ci tornerei sicuramente\n",
            ".\n",
            "5\n",
            "Ho soggiornato nell'hotel Acca Palace per una sola notte con il mio fidanzato per andare ad un concerto. La posizione di certo non è delle migliori, ma a me interessava perché vicina al luogo del concerto. Abbiamo trovato una bella struttura, con una camera ampia, ben arredata e pulita, con un bel balconcino! La colazione poi è il top: vasta scelta, sia dolce che salato, ed ottima qualità! Consigliato a chi non ha necessità di stare in pieno centro (anche se è a due passi dalla fermata della metropolitana, che è una grandissima comodità!).\n",
            "6\n",
            "Struttura a due passi dalla stazione di mestre. comodissima per raggiungere venezia. stanza pulita.ascensore interno per raggiungere i piani superiori. personale gentile e disponibile. wifi gratuito. non ho usufruito della colazione.\n",
            "7\n",
            "Ho transitato in questa struttura per qualche ora perché abbiamo fittato una sala con cena annessa. La struttura è mozzafiato,si affaccia su capodimonte dove si gode di un panorama paragonabile a pochi altri. Purtroppo è ubicato in un posto raggiungibile solo in auto e dopo aver percorso una strada stretta a doppio senso di marcia. In compenso dispone di posti auto in abbondanza . La valutazione della struttura è limitata a quanto visto,e l'impressione è ottima.La cena se pur a buffet è stata buona ed abbondante,poi dispone di un bar accogliente su una comoda terrazza verandata. Le 5 stelle per quel che ho visto sono meritate!!\n",
            "8\n",
            "un ottimo hotel in zona centrale,molto particolare e carino,personale gentilissimo,prezzi contenuti\n",
            "a due passi dalla stazione di porta susa,con ristoranti vicinissimi,colazione mega abbondante,comprensiva di dolce e salato,camere ampie con balcone,unico neo lo scarico del wc che scrosciava tutta la notte\n",
            "9\n",
            "Sono stato all hotel la Pergola l, estate scorsa con mia moglie e mia figlia di 3 anni, non ero mai stato a castellabate in vacanza e sono capitato per caso in questo grazioso alberghetto. In verità ci siamo trovati molto bene l hotel è in in zone centralissima e a pochi metri dalla spiaggia, proprio quello che cercavamo avendo una bimba piccola, a parte questo ho trovato del personale gentile e disponibile per qualsiasi esigenza, le camere non sono molto grandi ma confortevoli, il cibo molto buono abbiamo fatto la mezza pensione e il menù era sempre vario e la cucina tradizionale. Che dire ci siamo trovati bene e penso proprio che ci ritorneremo!\n",
            "\n",
            "\n",
            "10\n",
            "Prima volta in questo Hotel, è stata un'esperienza molto piacevole. La lobby è ok ma il personale è stato ottimo. Sempre fuori per aiutarvi. Le camere erano pulite, di buone dimensioni. Anche le stanze da bagno erano buone, con una bella vasca idromassaggio per rilassarsi dopo un lungo volo. Molto ben situato proprio accanto alla stazione centrale. Buoni posti per mangiare nei dintorni. L'unica cosa che non mi è piaciuta è la lunga passeggiata per la camera dall'ascensore. Il servizio in camera era buono e assolutamente sul tempo come ho ordinato delle bevande/ di cibo 2 ore in anticipo. Ci sarebbe piaciuto provare il centro benessere ma è in costruzione.\n",
            "11\n",
            "Abbiamo soggiornato in questo hotel prima e guardare avanti, al nostro ritorno. L'hotel è incantevole, e la camera era ottima. Un paio di \"critiche: la vasca idromassaggio non funzionava nella nostra camera, e abbiamo sentito il feedback da un altro ospite. In aggiunta, un paio di gli asciugamani erano molto usurati, e io non ti aspetteresti che da questo tipo di hotel.\n",
            "Detto questo, però, ci tornerei senza alcuna ambivalenza. Le camere sono confortevoli e pulite e la colazione è ottima.\n",
            "12\n",
            "Un soggiorno a Lido soltanto per due notti mi ha lasciato che vogliono più. Il Panorama Hotel offre splendide vedute di Venezia, che dista solo un breve tragitto in autobus di acqua lontano. Il personale era estremamente cordiale e le camere pulite. Consiglio vivamente l'escursione in barca gratuita a Murano. Non solo è stato il giro in barca molto bella, un breve gratuitamente la visualizzazione del talentuoso vetro veneziano accessori lavorando, valeva il viaggio.\n",
            "13\n",
            "2 Notti in questo hotel è stata appena sufficiente. Più di questo sarebbe insopportabile. La camera era ben arredata e moderna, e che era buono. Tuttavia, quando la prima volta che siamo andati fino alla camera, c'era un vassoio sporca di servizio in camera proprio lì davanti alla porta. Non è un buon segno. Poi, quando mi sono trasferito al telefono per collegare la mia iPad, c'era il pane briciole o sostanze sabbiose sul comodino. Ho subito trovato un asciugamano e pulita bagnata tutta superficie all'interno della camera. L'aspetto più deludente era il \" impietosa/atteggiamento freddo \" verso gli ospiti provenienti da quasi tutto il personale, il personale della reception, ristorante e bar. Essa potrebbe essere un questioni razziali qui? Non fare - bianco agli ospiti di ricevere trattamenti diversi? Milano non mi ha fascino, e, inoltre, ha confermato questo hotel la mia percezione sulla città.\n",
            "14\n",
            "Ottima la posizione a pochissimi passi dall'ingresso laterale della stazione, di sera la zona è un pò critica, ma ciò è normale intorno a tutte le stazioni ferroviarie delle grandi città. Il personale è molto cortese ed efficiente. Pulito e ben curato nelle camere e negli spazi comuni. Ricca e di qualità la colazione, buono anche il ristorante interno. Copertura telefonica e Wifi un pò oscillante. Nel complesso un ottimo tre stelle.\n",
            "15\n",
            "Ottimo hotel situato in posizione comoda per girare Torino a piedi.\n",
            "Camera e bagno abbastanza spaziosi e puliti.\n",
            "Grande cortesia dello staff\n",
            "Colazione abbondante e varia.\n",
            "Ottimo rapporto qualità prezzo \n",
            "Parcheggio per auto a pagamento molto comodo.\n",
            "Ci tornerei volentieri! Complimenti \n",
            "16\n",
            "Sgradevole hotel da molti punti di vista! Nella piccolissima camera “matrimoniale superior” dotata di letto “alla francese” e di un solo comodino spiccava una fastidiosa colonna portante... per non parlare della finta cortesia del personale, della difficoltà a trovare un posteggio, peraltro carissimo, dei 5 euro a persona al giorno estorti come “tassa di soggiorno”. \n",
            "E che dire di uno degli strettissimi ascendori cigolanti o della colazione che offriva anche maleodoranti bicchieri? \n",
            "E poi il povero Mozart che c’entra con questo posto? Leggerezza, eleganza e genialità del compositore austriaco nulla hanno a che fare con questo brutto albergo!!!\n",
            "17\n",
            "Ho prenotato un soggiorno di 4 notti per il compleanno di mia moglie attraverso le Vacanze di BA come ci siamo sempre stati eccellenti. Ho guardato molto pochi opzioni per alberghi sulle BA sito, cross-controllato su Trip Advisor e Ai Mori d'Oriente è apparso il meglio.\n",
            "\n",
            "Siamo arrivati in taxi pre-prenotato di acqua dall'aeroporto. Non è economico ma barrelling lungo in un lancio rapido motore di notte con il vento nei capelli - per essere lasciati proprio fuori dal vostro hotel - è il modo migliore per iniziare una vacanza.\n",
            "\n",
            "L'hotel si trova in un tranquillo canale entro un labirinto di vie navigabili stretta, che ci è sembrato la migliore ubicazione. La gentile ragazza dalla società di taxi d'acqua descritti Venezia come una piccola città \" - a forma di pesce (testa sul lato ovest, la coda a est) e con il nostro hotel posizionato verso la parte superiore.\n",
            "\n",
            "Ci sono un sacco di ristoranti e caffè a due passi, ma è solo un 10-15 minuti di passeggiata per i vicoli e canali navigabili oltre le zone turistiche intorno a Piazza San Marco, il Ponte di Rialto e oltre.\n",
            "\n",
            "All'interno c'è un'influenza araba per l'arredamento con archi in stile moresco e mobili intagliati, e un bar molto accogliente che è come tornare indietro in Casablanca del 1940. La sera, potete sedervi fuori per un drink e godersi il motorino occasionali lanci puttering nelle vicinanze. Gli ospiti sembravano essere principalmente americani, inglesi e tedeschi.\n",
            "\n",
            "Il personale era senza eccezione, immancabilmente accogliente e disponibile. Essi eseguire un viaggio in barca di sera per sperimentare il Grand Canal da sunset, che è stato molto divertente per 30 euro a testa. C'era anche un viaggio gratuito per vedere le vetrerie dell'isola di Murano, ma non siamo andati. La colazione era a buffet (con torta al cioccolato inaspettato!) e può essere preso nel cortile giardino dopo 08:30, che ci è piaciuto molto.\n",
            "\n",
            "Hotel è stato superlativo, Venezia era incredibile. Andateci adesso - che cosa stai aspettando?!\n",
            "18\n",
            "Ho soggiornato in questo hotel qualche tempo fa per una settimana con il mio compagno. Splendido tutto, dall'accoglienza, alle camere belle pulite, al cibo di ottima qualità. Il personale é stato sempre gentile, ma soprattutto al ristorante. La parte della spa é stupenda. C'è tutto ed é molto grande. Oltre alla SPA all'interno c'è anche la piscina salata che si può prenotare e quindi la si può godere in tranquillità con al max un'altra coppia. Anche la piscina esterna e il parco che circonda l'hotel sono ben curati e piacevoli. Da quando abbiamo soggiornato in questo hotel, io e il mio compagno, abbiamo girato molto la Toscana, ma un albergo così completo non l'abbiamo più trovato. É da provare, noi ci torneremo!\n",
            "19\n",
            "Appena arrivati questa mattina, questo Hotel è uno dei la unefficace regalati alloggiato in assoluto. Il personale era incantevole, le camere sono incantevoli, proprio su un tranquillo canale, vicino a Piazza San Marco e da un sacco di ristoranti e negozi, al tempo stesso molto tranquillamente situato. Non esitate a soggiornare qui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YO3pBtaGdkX",
        "outputId": "090e1583-9565-4d9d-a046-2e4d72fa82d8"
      },
      "source": [
        "mask = [len(tokenizer.tokenize(df.iloc[i].text)) < 480 for i in range(len(df))]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB7Cou-wGsoN"
      },
      "source": [
        "df = df[mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG4FIlIcG7tU",
        "outputId": "8836be0b-7140-4376-b93c-5e93495895fa"
      },
      "source": [
        "np.unique(df['class'],return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['neg', 'pos'], dtype=object), array([ 8787, 19201]))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P__DDdexG_bG"
      },
      "source": [
        "positive_reviews_mask = df['class'] == 'pos'\n",
        "negative_reviews_mask = df['class'] == 'neg'\n",
        "\n",
        "ids_positive = df.index[positive_reviews_mask].to_list()[:6000]\n",
        "ids_negative = df.index[negative_reviews_mask].to_list()[:6000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "a7CvVOx2HS-G",
        "outputId": "6e97515f-92da-4d3a-9d9e-908b99653696"
      },
      "source": [
        "df = df.loc[ids_positive + ids_negative]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Siamo stati qui per 1 notte prima della nostra...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hotel è ben posizionato per visitare Torino. A...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>All'arrivo la cordialità e disponibilità dello...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbiamo soggiornato per due notti alla fine de...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ho soggiornato nell'hotel Acca Palace per una ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19675</th>\n",
              "      <td>Hotel a Bad, pessima posizione, non confortevo...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19677</th>\n",
              "      <td>4 stelle solo nel nome e non so nemmeno come a...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19681</th>\n",
              "      <td>La struttura si trova in località Sant'Andrea,...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19682</th>\n",
              "      <td>L'hotel si trova a pochi metri dalla fermata d...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19683</th>\n",
              "      <td>Siamo andati in 1 Maggio, 2012. L'unica cosa c...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text class\n",
              "1      Siamo stati qui per 1 notte prima della nostra...   pos\n",
              "2      Hotel è ben posizionato per visitare Torino. A...   pos\n",
              "3      All'arrivo la cordialità e disponibilità dello...   pos\n",
              "4      Abbiamo soggiornato per due notti alla fine de...   pos\n",
              "5      Ho soggiornato nell'hotel Acca Palace per una ...   pos\n",
              "...                                                  ...   ...\n",
              "19675  Hotel a Bad, pessima posizione, non confortevo...   neg\n",
              "19677  4 stelle solo nel nome e non so nemmeno come a...   neg\n",
              "19681  La struttura si trova in località Sant'Andrea,...   neg\n",
              "19682  L'hotel si trova a pochi metri dalla fermata d...   neg\n",
              "19683  Siamo andati in 1 Maggio, 2012. L'unica cosa c...   neg\n",
              "\n",
              "[12000 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-3bzwIeHagj",
        "outputId": "8fe6f1fe-e070-49c8-c924-612d563e8ff6"
      },
      "source": [
        "np.unique(df['class'],return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['neg', 'pos'], dtype=object), array([6000, 6000]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1idACb9Hp6i"
      },
      "source": [
        "reviews = df.text.to_list()\n",
        "labels = df['class'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER1aCAosH1HX",
        "outputId": "16d04206-b1a8-4547-e98f-d3f9e19a31e5"
      },
      "source": [
        "it_bert_model.finetune(reviews, labels=labels, optimizer_parameters=dict(lr=5e-5), batch_size=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding...\n",
            "Preparing batches...\n",
            "Preparing optimizer...\n",
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "  Batch    25  of  3,000.    Elapsed: 0:00:06.\n",
            "  Batch    50  of  3,000.    Elapsed: 0:00:13.\n",
            "  Batch    75  of  3,000.    Elapsed: 0:00:19.\n",
            "  Batch   100  of  3,000.    Elapsed: 0:00:25.\n",
            "  Batch   125  of  3,000.    Elapsed: 0:00:32.\n",
            "  Batch   150  of  3,000.    Elapsed: 0:00:38.\n",
            "  Batch   175  of  3,000.    Elapsed: 0:00:45.\n",
            "  Batch   200  of  3,000.    Elapsed: 0:00:51.\n",
            "  Batch   225  of  3,000.    Elapsed: 0:00:58.\n",
            "  Batch   250  of  3,000.    Elapsed: 0:01:04.\n",
            "  Batch   275  of  3,000.    Elapsed: 0:01:11.\n",
            "  Batch   300  of  3,000.    Elapsed: 0:01:17.\n",
            "  Batch   325  of  3,000.    Elapsed: 0:01:24.\n",
            "  Batch   350  of  3,000.    Elapsed: 0:01:31.\n",
            "  Batch   375  of  3,000.    Elapsed: 0:01:37.\n",
            "  Batch   400  of  3,000.    Elapsed: 0:01:44.\n",
            "  Batch   425  of  3,000.    Elapsed: 0:01:51.\n",
            "  Batch   450  of  3,000.    Elapsed: 0:01:57.\n",
            "  Batch   475  of  3,000.    Elapsed: 0:02:04.\n",
            "  Batch   500  of  3,000.    Elapsed: 0:02:11.\n",
            "  Batch   525  of  3,000.    Elapsed: 0:02:18.\n",
            "  Batch   550  of  3,000.    Elapsed: 0:02:25.\n",
            "  Batch   575  of  3,000.    Elapsed: 0:02:31.\n",
            "  Batch   600  of  3,000.    Elapsed: 0:02:38.\n",
            "  Batch   625  of  3,000.    Elapsed: 0:02:45.\n",
            "  Batch   650  of  3,000.    Elapsed: 0:02:52.\n",
            "  Batch   675  of  3,000.    Elapsed: 0:02:59.\n",
            "  Batch   700  of  3,000.    Elapsed: 0:03:06.\n",
            "  Batch   725  of  3,000.    Elapsed: 0:03:12.\n",
            "  Batch   750  of  3,000.    Elapsed: 0:03:19.\n",
            "  Batch   775  of  3,000.    Elapsed: 0:03:26.\n",
            "  Batch   800  of  3,000.    Elapsed: 0:03:33.\n",
            "  Batch   825  of  3,000.    Elapsed: 0:03:40.\n",
            "  Batch   850  of  3,000.    Elapsed: 0:03:47.\n",
            "  Batch   875  of  3,000.    Elapsed: 0:03:54.\n",
            "  Batch   900  of  3,000.    Elapsed: 0:04:01.\n",
            "  Batch   925  of  3,000.    Elapsed: 0:04:08.\n",
            "  Batch   950  of  3,000.    Elapsed: 0:04:14.\n",
            "  Batch   975  of  3,000.    Elapsed: 0:04:21.\n",
            "  Batch 1,000  of  3,000.    Elapsed: 0:04:28.\n",
            "  Batch 1,025  of  3,000.    Elapsed: 0:04:35.\n",
            "  Batch 1,050  of  3,000.    Elapsed: 0:04:42.\n",
            "  Batch 1,075  of  3,000.    Elapsed: 0:04:49.\n",
            "  Batch 1,100  of  3,000.    Elapsed: 0:04:56.\n",
            "  Batch 1,125  of  3,000.    Elapsed: 0:05:03.\n",
            "  Batch 1,150  of  3,000.    Elapsed: 0:05:10.\n",
            "  Batch 1,175  of  3,000.    Elapsed: 0:05:17.\n",
            "  Batch 1,200  of  3,000.    Elapsed: 0:05:23.\n",
            "  Batch 1,225  of  3,000.    Elapsed: 0:05:30.\n",
            "  Batch 1,250  of  3,000.    Elapsed: 0:05:37.\n",
            "  Batch 1,275  of  3,000.    Elapsed: 0:05:44.\n",
            "  Batch 1,300  of  3,000.    Elapsed: 0:05:51.\n",
            "  Batch 1,325  of  3,000.    Elapsed: 0:05:58.\n",
            "  Batch 1,350  of  3,000.    Elapsed: 0:06:05.\n",
            "  Batch 1,375  of  3,000.    Elapsed: 0:06:12.\n",
            "  Batch 1,400  of  3,000.    Elapsed: 0:06:19.\n",
            "  Batch 1,425  of  3,000.    Elapsed: 0:06:26.\n",
            "  Batch 1,450  of  3,000.    Elapsed: 0:06:32.\n",
            "  Batch 1,475  of  3,000.    Elapsed: 0:06:39.\n",
            "  Batch 1,500  of  3,000.    Elapsed: 0:06:46.\n",
            "  Batch 1,525  of  3,000.    Elapsed: 0:06:53.\n",
            "  Batch 1,550  of  3,000.    Elapsed: 0:07:00.\n",
            "  Batch 1,575  of  3,000.    Elapsed: 0:07:07.\n",
            "  Batch 1,600  of  3,000.    Elapsed: 0:07:14.\n",
            "  Batch 1,625  of  3,000.    Elapsed: 0:07:21.\n",
            "  Batch 1,650  of  3,000.    Elapsed: 0:07:28.\n",
            "  Batch 1,675  of  3,000.    Elapsed: 0:07:34.\n",
            "  Batch 1,700  of  3,000.    Elapsed: 0:07:41.\n",
            "  Batch 1,725  of  3,000.    Elapsed: 0:07:48.\n",
            "  Batch 1,750  of  3,000.    Elapsed: 0:07:55.\n",
            "  Batch 1,775  of  3,000.    Elapsed: 0:08:02.\n",
            "  Batch 1,800  of  3,000.    Elapsed: 0:08:09.\n",
            "  Batch 1,825  of  3,000.    Elapsed: 0:08:16.\n",
            "  Batch 1,850  of  3,000.    Elapsed: 0:08:23.\n",
            "  Batch 1,875  of  3,000.    Elapsed: 0:08:29.\n",
            "  Batch 1,900  of  3,000.    Elapsed: 0:08:36.\n",
            "  Batch 1,925  of  3,000.    Elapsed: 0:08:43.\n",
            "  Batch 1,950  of  3,000.    Elapsed: 0:08:50.\n",
            "  Batch 1,975  of  3,000.    Elapsed: 0:08:57.\n",
            "  Batch 2,000  of  3,000.    Elapsed: 0:09:04.\n",
            "  Batch 2,025  of  3,000.    Elapsed: 0:09:11.\n",
            "  Batch 2,050  of  3,000.    Elapsed: 0:09:18.\n",
            "  Batch 2,075  of  3,000.    Elapsed: 0:09:24.\n",
            "  Batch 2,100  of  3,000.    Elapsed: 0:09:31.\n",
            "  Batch 2,125  of  3,000.    Elapsed: 0:09:38.\n",
            "  Batch 2,150  of  3,000.    Elapsed: 0:09:45.\n",
            "  Batch 2,175  of  3,000.    Elapsed: 0:09:52.\n",
            "  Batch 2,200  of  3,000.    Elapsed: 0:09:59.\n",
            "  Batch 2,225  of  3,000.    Elapsed: 0:10:06.\n",
            "  Batch 2,250  of  3,000.    Elapsed: 0:10:13.\n",
            "  Batch 2,275  of  3,000.    Elapsed: 0:10:20.\n",
            "  Batch 2,300  of  3,000.    Elapsed: 0:10:26.\n",
            "  Batch 2,325  of  3,000.    Elapsed: 0:10:33.\n",
            "  Batch 2,350  of  3,000.    Elapsed: 0:10:40.\n",
            "  Batch 2,375  of  3,000.    Elapsed: 0:10:47.\n",
            "  Batch 2,400  of  3,000.    Elapsed: 0:10:54.\n",
            "  Batch 2,425  of  3,000.    Elapsed: 0:11:01.\n",
            "  Batch 2,450  of  3,000.    Elapsed: 0:11:08.\n",
            "  Batch 2,475  of  3,000.    Elapsed: 0:11:15.\n",
            "  Batch 2,500  of  3,000.    Elapsed: 0:11:21.\n",
            "  Batch 2,525  of  3,000.    Elapsed: 0:11:28.\n",
            "  Batch 2,550  of  3,000.    Elapsed: 0:11:35.\n",
            "  Batch 2,575  of  3,000.    Elapsed: 0:11:42.\n",
            "  Batch 2,600  of  3,000.    Elapsed: 0:11:49.\n",
            "  Batch 2,625  of  3,000.    Elapsed: 0:11:56.\n",
            "  Batch 2,650  of  3,000.    Elapsed: 0:12:03.\n",
            "  Batch 2,675  of  3,000.    Elapsed: 0:12:10.\n",
            "  Batch 2,700  of  3,000.    Elapsed: 0:12:17.\n",
            "  Batch 2,725  of  3,000.    Elapsed: 0:12:23.\n",
            "  Batch 2,750  of  3,000.    Elapsed: 0:12:30.\n",
            "  Batch 2,775  of  3,000.    Elapsed: 0:12:37.\n",
            "  Batch 2,800  of  3,000.    Elapsed: 0:12:44.\n",
            "  Batch 2,825  of  3,000.    Elapsed: 0:12:51.\n",
            "  Batch 2,850  of  3,000.    Elapsed: 0:12:58.\n",
            "  Batch 2,875  of  3,000.    Elapsed: 0:13:05.\n",
            "  Batch 2,900  of  3,000.    Elapsed: 0:13:12.\n",
            "  Batch 2,925  of  3,000.    Elapsed: 0:13:18.\n",
            "  Batch 2,950  of  3,000.    Elapsed: 0:13:25.\n",
            "  Batch 2,975  of  3,000.    Elapsed: 0:13:32.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:13:39\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of  3,000.    Elapsed: 0:00:07.\n",
            "  Batch    50  of  3,000.    Elapsed: 0:00:14.\n",
            "  Batch    75  of  3,000.    Elapsed: 0:00:21.\n",
            "  Batch   100  of  3,000.    Elapsed: 0:00:28.\n",
            "  Batch   125  of  3,000.    Elapsed: 0:00:34.\n",
            "  Batch   150  of  3,000.    Elapsed: 0:00:41.\n",
            "  Batch   175  of  3,000.    Elapsed: 0:00:48.\n",
            "  Batch   200  of  3,000.    Elapsed: 0:00:55.\n",
            "  Batch   225  of  3,000.    Elapsed: 0:01:02.\n",
            "  Batch   250  of  3,000.    Elapsed: 0:01:09.\n",
            "  Batch   275  of  3,000.    Elapsed: 0:01:16.\n",
            "  Batch   300  of  3,000.    Elapsed: 0:01:23.\n",
            "  Batch   325  of  3,000.    Elapsed: 0:01:30.\n",
            "  Batch   350  of  3,000.    Elapsed: 0:01:36.\n",
            "  Batch   375  of  3,000.    Elapsed: 0:01:43.\n",
            "  Batch   400  of  3,000.    Elapsed: 0:01:50.\n",
            "  Batch   425  of  3,000.    Elapsed: 0:01:57.\n",
            "  Batch   450  of  3,000.    Elapsed: 0:02:04.\n",
            "  Batch   475  of  3,000.    Elapsed: 0:02:11.\n",
            "  Batch   500  of  3,000.    Elapsed: 0:02:18.\n",
            "  Batch   525  of  3,000.    Elapsed: 0:02:25.\n",
            "  Batch   550  of  3,000.    Elapsed: 0:02:31.\n",
            "  Batch   575  of  3,000.    Elapsed: 0:02:38.\n",
            "  Batch   600  of  3,000.    Elapsed: 0:02:45.\n",
            "  Batch   625  of  3,000.    Elapsed: 0:02:52.\n",
            "  Batch   650  of  3,000.    Elapsed: 0:02:59.\n",
            "  Batch   675  of  3,000.    Elapsed: 0:03:06.\n",
            "  Batch   700  of  3,000.    Elapsed: 0:03:13.\n",
            "  Batch   725  of  3,000.    Elapsed: 0:03:20.\n",
            "  Batch   750  of  3,000.    Elapsed: 0:03:27.\n",
            "  Batch   775  of  3,000.    Elapsed: 0:03:33.\n",
            "  Batch   800  of  3,000.    Elapsed: 0:03:40.\n",
            "  Batch   825  of  3,000.    Elapsed: 0:03:47.\n",
            "  Batch   850  of  3,000.    Elapsed: 0:03:54.\n",
            "  Batch   875  of  3,000.    Elapsed: 0:04:01.\n",
            "  Batch   900  of  3,000.    Elapsed: 0:04:08.\n",
            "  Batch   925  of  3,000.    Elapsed: 0:04:15.\n",
            "  Batch   950  of  3,000.    Elapsed: 0:04:22.\n",
            "  Batch   975  of  3,000.    Elapsed: 0:04:28.\n",
            "  Batch 1,000  of  3,000.    Elapsed: 0:04:35.\n",
            "  Batch 1,025  of  3,000.    Elapsed: 0:04:42.\n",
            "  Batch 1,050  of  3,000.    Elapsed: 0:04:49.\n",
            "  Batch 1,075  of  3,000.    Elapsed: 0:04:56.\n",
            "  Batch 1,100  of  3,000.    Elapsed: 0:05:03.\n",
            "  Batch 1,125  of  3,000.    Elapsed: 0:05:10.\n",
            "  Batch 1,150  of  3,000.    Elapsed: 0:05:17.\n",
            "  Batch 1,175  of  3,000.    Elapsed: 0:05:23.\n",
            "  Batch 1,200  of  3,000.    Elapsed: 0:05:30.\n",
            "  Batch 1,225  of  3,000.    Elapsed: 0:05:37.\n",
            "  Batch 1,250  of  3,000.    Elapsed: 0:05:44.\n",
            "  Batch 1,275  of  3,000.    Elapsed: 0:05:51.\n",
            "  Batch 1,300  of  3,000.    Elapsed: 0:05:58.\n",
            "  Batch 1,325  of  3,000.    Elapsed: 0:06:05.\n",
            "  Batch 1,350  of  3,000.    Elapsed: 0:06:12.\n",
            "  Batch 1,375  of  3,000.    Elapsed: 0:06:19.\n",
            "  Batch 1,400  of  3,000.    Elapsed: 0:06:25.\n",
            "  Batch 1,425  of  3,000.    Elapsed: 0:06:32.\n",
            "  Batch 1,450  of  3,000.    Elapsed: 0:06:39.\n",
            "  Batch 1,475  of  3,000.    Elapsed: 0:06:46.\n",
            "  Batch 1,500  of  3,000.    Elapsed: 0:06:53.\n",
            "  Batch 1,525  of  3,000.    Elapsed: 0:07:00.\n",
            "  Batch 1,550  of  3,000.    Elapsed: 0:07:07.\n",
            "  Batch 1,575  of  3,000.    Elapsed: 0:07:14.\n",
            "  Batch 1,600  of  3,000.    Elapsed: 0:07:21.\n",
            "  Batch 1,625  of  3,000.    Elapsed: 0:07:27.\n",
            "  Batch 1,650  of  3,000.    Elapsed: 0:07:34.\n",
            "  Batch 1,675  of  3,000.    Elapsed: 0:07:41.\n",
            "  Batch 1,700  of  3,000.    Elapsed: 0:07:48.\n",
            "  Batch 1,725  of  3,000.    Elapsed: 0:07:55.\n",
            "  Batch 1,750  of  3,000.    Elapsed: 0:08:02.\n",
            "  Batch 1,775  of  3,000.    Elapsed: 0:08:09.\n",
            "  Batch 1,800  of  3,000.    Elapsed: 0:08:16.\n",
            "  Batch 1,825  of  3,000.    Elapsed: 0:08:23.\n",
            "  Batch 1,850  of  3,000.    Elapsed: 0:08:29.\n",
            "  Batch 1,875  of  3,000.    Elapsed: 0:08:36.\n",
            "  Batch 1,900  of  3,000.    Elapsed: 0:08:43.\n",
            "  Batch 1,925  of  3,000.    Elapsed: 0:08:50.\n",
            "  Batch 1,950  of  3,000.    Elapsed: 0:08:57.\n",
            "  Batch 1,975  of  3,000.    Elapsed: 0:09:04.\n",
            "  Batch 2,000  of  3,000.    Elapsed: 0:09:11.\n",
            "  Batch 2,025  of  3,000.    Elapsed: 0:09:18.\n",
            "  Batch 2,050  of  3,000.    Elapsed: 0:09:24.\n",
            "  Batch 2,075  of  3,000.    Elapsed: 0:09:31.\n",
            "  Batch 2,100  of  3,000.    Elapsed: 0:09:38.\n",
            "  Batch 2,125  of  3,000.    Elapsed: 0:09:45.\n",
            "  Batch 2,150  of  3,000.    Elapsed: 0:09:52.\n",
            "  Batch 2,175  of  3,000.    Elapsed: 0:09:59.\n",
            "  Batch 2,200  of  3,000.    Elapsed: 0:10:06.\n",
            "  Batch 2,225  of  3,000.    Elapsed: 0:10:13.\n",
            "  Batch 2,250  of  3,000.    Elapsed: 0:10:19.\n",
            "  Batch 2,275  of  3,000.    Elapsed: 0:10:26.\n",
            "  Batch 2,300  of  3,000.    Elapsed: 0:10:33.\n",
            "  Batch 2,325  of  3,000.    Elapsed: 0:10:40.\n",
            "  Batch 2,350  of  3,000.    Elapsed: 0:10:47.\n",
            "  Batch 2,375  of  3,000.    Elapsed: 0:10:54.\n",
            "  Batch 2,400  of  3,000.    Elapsed: 0:11:01.\n",
            "  Batch 2,425  of  3,000.    Elapsed: 0:11:08.\n",
            "  Batch 2,450  of  3,000.    Elapsed: 0:11:15.\n",
            "  Batch 2,475  of  3,000.    Elapsed: 0:11:21.\n",
            "  Batch 2,500  of  3,000.    Elapsed: 0:11:28.\n",
            "  Batch 2,525  of  3,000.    Elapsed: 0:11:35.\n",
            "  Batch 2,550  of  3,000.    Elapsed: 0:11:42.\n",
            "  Batch 2,575  of  3,000.    Elapsed: 0:11:49.\n",
            "  Batch 2,600  of  3,000.    Elapsed: 0:11:56.\n",
            "  Batch 2,625  of  3,000.    Elapsed: 0:12:03.\n",
            "  Batch 2,650  of  3,000.    Elapsed: 0:12:10.\n",
            "  Batch 2,675  of  3,000.    Elapsed: 0:12:17.\n",
            "  Batch 2,700  of  3,000.    Elapsed: 0:12:23.\n",
            "  Batch 2,725  of  3,000.    Elapsed: 0:12:30.\n",
            "  Batch 2,750  of  3,000.    Elapsed: 0:12:37.\n",
            "  Batch 2,775  of  3,000.    Elapsed: 0:12:44.\n",
            "  Batch 2,800  of  3,000.    Elapsed: 0:12:51.\n",
            "  Batch 2,825  of  3,000.    Elapsed: 0:12:58.\n",
            "  Batch 2,850  of  3,000.    Elapsed: 0:13:05.\n",
            "  Batch 2,875  of  3,000.    Elapsed: 0:13:12.\n",
            "  Batch 2,900  of  3,000.    Elapsed: 0:13:18.\n",
            "  Batch 2,925  of  3,000.    Elapsed: 0:13:25.\n",
            "  Batch 2,950  of  3,000.    Elapsed: 0:13:32.\n",
            "  Batch 2,975  of  3,000.    Elapsed: 0:13:39.\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:13:46\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of  3,000.    Elapsed: 0:00:07.\n",
            "  Batch    50  of  3,000.    Elapsed: 0:00:14.\n",
            "  Batch    75  of  3,000.    Elapsed: 0:00:21.\n",
            "  Batch   100  of  3,000.    Elapsed: 0:00:28.\n",
            "  Batch   125  of  3,000.    Elapsed: 0:00:34.\n",
            "  Batch   150  of  3,000.    Elapsed: 0:00:41.\n",
            "  Batch   175  of  3,000.    Elapsed: 0:00:48.\n",
            "  Batch   200  of  3,000.    Elapsed: 0:00:55.\n",
            "  Batch   225  of  3,000.    Elapsed: 0:01:02.\n",
            "  Batch   250  of  3,000.    Elapsed: 0:01:09.\n",
            "  Batch   275  of  3,000.    Elapsed: 0:01:16.\n",
            "  Batch   300  of  3,000.    Elapsed: 0:01:23.\n",
            "  Batch   325  of  3,000.    Elapsed: 0:01:30.\n",
            "  Batch   350  of  3,000.    Elapsed: 0:01:36.\n",
            "  Batch   375  of  3,000.    Elapsed: 0:01:43.\n",
            "  Batch   400  of  3,000.    Elapsed: 0:01:50.\n",
            "  Batch   425  of  3,000.    Elapsed: 0:01:57.\n",
            "  Batch   450  of  3,000.    Elapsed: 0:02:04.\n",
            "  Batch   475  of  3,000.    Elapsed: 0:02:11.\n",
            "  Batch   500  of  3,000.    Elapsed: 0:02:18.\n",
            "  Batch   525  of  3,000.    Elapsed: 0:02:25.\n",
            "  Batch   550  of  3,000.    Elapsed: 0:02:31.\n",
            "  Batch   575  of  3,000.    Elapsed: 0:02:38.\n",
            "  Batch   600  of  3,000.    Elapsed: 0:02:45.\n",
            "  Batch   625  of  3,000.    Elapsed: 0:02:52.\n",
            "  Batch   650  of  3,000.    Elapsed: 0:02:59.\n",
            "  Batch   675  of  3,000.    Elapsed: 0:03:06.\n",
            "  Batch   700  of  3,000.    Elapsed: 0:03:13.\n",
            "  Batch   725  of  3,000.    Elapsed: 0:03:20.\n",
            "  Batch   750  of  3,000.    Elapsed: 0:03:27.\n",
            "  Batch   775  of  3,000.    Elapsed: 0:03:33.\n",
            "  Batch   800  of  3,000.    Elapsed: 0:03:40.\n",
            "  Batch   825  of  3,000.    Elapsed: 0:03:47.\n",
            "  Batch   850  of  3,000.    Elapsed: 0:03:54.\n",
            "  Batch   875  of  3,000.    Elapsed: 0:04:01.\n",
            "  Batch   900  of  3,000.    Elapsed: 0:04:08.\n",
            "  Batch   925  of  3,000.    Elapsed: 0:04:15.\n",
            "  Batch   950  of  3,000.    Elapsed: 0:04:22.\n",
            "  Batch   975  of  3,000.    Elapsed: 0:04:28.\n",
            "  Batch 1,000  of  3,000.    Elapsed: 0:04:35.\n",
            "  Batch 1,025  of  3,000.    Elapsed: 0:04:42.\n",
            "  Batch 1,050  of  3,000.    Elapsed: 0:04:49.\n",
            "  Batch 1,075  of  3,000.    Elapsed: 0:04:56.\n",
            "  Batch 1,100  of  3,000.    Elapsed: 0:05:03.\n",
            "  Batch 1,125  of  3,000.    Elapsed: 0:05:10.\n",
            "  Batch 1,150  of  3,000.    Elapsed: 0:05:17.\n",
            "  Batch 1,175  of  3,000.    Elapsed: 0:05:24.\n",
            "  Batch 1,200  of  3,000.    Elapsed: 0:05:30.\n",
            "  Batch 1,225  of  3,000.    Elapsed: 0:05:37.\n",
            "  Batch 1,250  of  3,000.    Elapsed: 0:05:44.\n",
            "  Batch 1,275  of  3,000.    Elapsed: 0:05:51.\n",
            "  Batch 1,300  of  3,000.    Elapsed: 0:05:58.\n",
            "  Batch 1,325  of  3,000.    Elapsed: 0:06:05.\n",
            "  Batch 1,350  of  3,000.    Elapsed: 0:06:12.\n",
            "  Batch 1,375  of  3,000.    Elapsed: 0:06:19.\n",
            "  Batch 1,400  of  3,000.    Elapsed: 0:06:25.\n",
            "  Batch 1,425  of  3,000.    Elapsed: 0:06:32.\n",
            "  Batch 1,450  of  3,000.    Elapsed: 0:06:39.\n",
            "  Batch 1,475  of  3,000.    Elapsed: 0:06:46.\n",
            "  Batch 1,500  of  3,000.    Elapsed: 0:06:53.\n",
            "  Batch 1,525  of  3,000.    Elapsed: 0:07:00.\n",
            "  Batch 1,550  of  3,000.    Elapsed: 0:07:07.\n",
            "  Batch 1,575  of  3,000.    Elapsed: 0:07:14.\n",
            "  Batch 1,600  of  3,000.    Elapsed: 0:07:21.\n",
            "  Batch 1,625  of  3,000.    Elapsed: 0:07:27.\n",
            "  Batch 1,650  of  3,000.    Elapsed: 0:07:34.\n",
            "  Batch 1,675  of  3,000.    Elapsed: 0:07:41.\n",
            "  Batch 1,700  of  3,000.    Elapsed: 0:07:48.\n",
            "  Batch 1,725  of  3,000.    Elapsed: 0:07:55.\n",
            "  Batch 1,750  of  3,000.    Elapsed: 0:08:02.\n",
            "  Batch 1,775  of  3,000.    Elapsed: 0:08:09.\n",
            "  Batch 1,800  of  3,000.    Elapsed: 0:08:16.\n",
            "  Batch 1,825  of  3,000.    Elapsed: 0:08:23.\n",
            "  Batch 1,850  of  3,000.    Elapsed: 0:08:29.\n",
            "  Batch 1,875  of  3,000.    Elapsed: 0:08:36.\n",
            "  Batch 1,900  of  3,000.    Elapsed: 0:08:43.\n",
            "  Batch 1,925  of  3,000.    Elapsed: 0:08:50.\n",
            "  Batch 1,950  of  3,000.    Elapsed: 0:08:57.\n",
            "  Batch 1,975  of  3,000.    Elapsed: 0:09:04.\n",
            "  Batch 2,000  of  3,000.    Elapsed: 0:09:11.\n",
            "  Batch 2,025  of  3,000.    Elapsed: 0:09:18.\n",
            "  Batch 2,050  of  3,000.    Elapsed: 0:09:25.\n",
            "  Batch 2,075  of  3,000.    Elapsed: 0:09:31.\n",
            "  Batch 2,100  of  3,000.    Elapsed: 0:09:38.\n",
            "  Batch 2,125  of  3,000.    Elapsed: 0:09:45.\n",
            "  Batch 2,150  of  3,000.    Elapsed: 0:09:52.\n",
            "  Batch 2,175  of  3,000.    Elapsed: 0:09:59.\n",
            "  Batch 2,200  of  3,000.    Elapsed: 0:10:06.\n",
            "  Batch 2,225  of  3,000.    Elapsed: 0:10:13.\n",
            "  Batch 2,250  of  3,000.    Elapsed: 0:10:20.\n",
            "  Batch 2,275  of  3,000.    Elapsed: 0:10:26.\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "  Batch 2,300  of  3,000.    Elapsed: 0:10:33.\n",
            "  Batch 2,325  of  3,000.    Elapsed: 0:10:40.\n",
            "  Batch 2,350  of  3,000.    Elapsed: 0:10:47.\n",
            "  Batch 2,375  of  3,000.    Elapsed: 0:10:54.\n",
            "  Batch 2,400  of  3,000.    Elapsed: 0:11:01.\n",
            "  Batch 2,425  of  3,000.    Elapsed: 0:11:08.\n",
            "  Batch 2,450  of  3,000.    Elapsed: 0:11:15.\n",
            "  Batch 2,475  of  3,000.    Elapsed: 0:11:22.\n",
            "  Batch 2,500  of  3,000.    Elapsed: 0:11:28.\n",
            "  Batch 2,525  of  3,000.    Elapsed: 0:11:35.\n",
            "  Batch 2,550  of  3,000.    Elapsed: 0:11:42.\n",
            "  Batch 2,575  of  3,000.    Elapsed: 0:11:49.\n",
            "  Batch 2,600  of  3,000.    Elapsed: 0:11:56.\n",
            "  Batch 2,625  of  3,000.    Elapsed: 0:12:03.\n",
            "  Batch 2,650  of  3,000.    Elapsed: 0:12:10.\n",
            "  Batch 2,675  of  3,000.    Elapsed: 0:12:17.\n",
            "  Batch 2,700  of  3,000.    Elapsed: 0:12:24.\n",
            "  Batch 2,725  of  3,000.    Elapsed: 0:12:30.\n",
            "  Batch 2,750  of  3,000.    Elapsed: 0:12:37.\n",
            "  Batch 2,775  of  3,000.    Elapsed: 0:12:44.\n",
            "  Batch 2,800  of  3,000.    Elapsed: 0:12:51.\n",
            "  Batch 2,825  of  3,000.    Elapsed: 0:12:58.\n",
            "  Batch 2,850  of  3,000.    Elapsed: 0:13:05.\n",
            "  Batch 2,875  of  3,000.    Elapsed: 0:13:12.\n",
            "  Batch 2,900  of  3,000.    Elapsed: 0:13:19.\n",
            "  Batch 2,925  of  3,000.    Elapsed: 0:13:25.\n",
            "  Batch 2,950  of  3,000.    Elapsed: 0:13:32.\n",
            "  Batch 2,975  of  3,000.    Elapsed: 0:13:39.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:13:46\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    25  of  3,000.    Elapsed: 0:00:07.\n",
            "  Batch    50  of  3,000.    Elapsed: 0:00:14.\n",
            "  Batch    75  of  3,000.    Elapsed: 0:00:21.\n",
            "  Batch   100  of  3,000.    Elapsed: 0:00:28.\n",
            "  Batch   125  of  3,000.    Elapsed: 0:00:34.\n",
            "  Batch   150  of  3,000.    Elapsed: 0:00:41.\n",
            "  Batch   175  of  3,000.    Elapsed: 0:00:48.\n",
            "  Batch   200  of  3,000.    Elapsed: 0:00:55.\n",
            "  Batch   225  of  3,000.    Elapsed: 0:01:02.\n",
            "  Batch   250  of  3,000.    Elapsed: 0:01:09.\n",
            "  Batch   275  of  3,000.    Elapsed: 0:01:16.\n",
            "  Batch   300  of  3,000.    Elapsed: 0:01:23.\n",
            "  Batch   325  of  3,000.    Elapsed: 0:01:29.\n",
            "  Batch   350  of  3,000.    Elapsed: 0:01:36.\n",
            "  Batch   375  of  3,000.    Elapsed: 0:01:43.\n",
            "  Batch   400  of  3,000.    Elapsed: 0:01:50.\n",
            "  Batch   425  of  3,000.    Elapsed: 0:01:57.\n",
            "  Batch   450  of  3,000.    Elapsed: 0:02:04.\n",
            "  Batch   475  of  3,000.    Elapsed: 0:02:11.\n",
            "  Batch   500  of  3,000.    Elapsed: 0:02:18.\n",
            "  Batch   525  of  3,000.    Elapsed: 0:02:25.\n",
            "  Batch   550  of  3,000.    Elapsed: 0:02:31.\n",
            "  Batch   575  of  3,000.    Elapsed: 0:02:38.\n",
            "  Batch   600  of  3,000.    Elapsed: 0:02:45.\n",
            "  Batch   625  of  3,000.    Elapsed: 0:02:52.\n",
            "  Batch   650  of  3,000.    Elapsed: 0:02:59.\n",
            "  Batch   675  of  3,000.    Elapsed: 0:03:06.\n",
            "  Batch   700  of  3,000.    Elapsed: 0:03:13.\n",
            "  Batch   725  of  3,000.    Elapsed: 0:03:20.\n",
            "  Batch   750  of  3,000.    Elapsed: 0:03:26.\n",
            "  Batch   775  of  3,000.    Elapsed: 0:03:33.\n",
            "  Batch   800  of  3,000.    Elapsed: 0:03:40.\n",
            "  Batch   825  of  3,000.    Elapsed: 0:03:47.\n",
            "  Batch   850  of  3,000.    Elapsed: 0:03:54.\n",
            "  Batch   875  of  3,000.    Elapsed: 0:04:01.\n",
            "  Batch   900  of  3,000.    Elapsed: 0:04:08.\n",
            "  Batch   925  of  3,000.    Elapsed: 0:04:15.\n",
            "  Batch   950  of  3,000.    Elapsed: 0:04:22.\n",
            "  Batch   975  of  3,000.    Elapsed: 0:04:28.\n",
            "  Batch 1,000  of  3,000.    Elapsed: 0:04:35.\n",
            "  Batch 1,025  of  3,000.    Elapsed: 0:04:42.\n",
            "  Batch 1,050  of  3,000.    Elapsed: 0:04:49.\n",
            "  Batch 1,075  of  3,000.    Elapsed: 0:04:56.\n",
            "  Batch 1,100  of  3,000.    Elapsed: 0:05:03.\n",
            "  Batch 1,125  of  3,000.    Elapsed: 0:05:10.\n",
            "  Batch 1,150  of  3,000.    Elapsed: 0:05:17.\n",
            "  Batch 1,175  of  3,000.    Elapsed: 0:05:24.\n",
            "  Batch 1,200  of  3,000.    Elapsed: 0:05:30.\n",
            "  Batch 1,225  of  3,000.    Elapsed: 0:05:37.\n",
            "  Batch 1,250  of  3,000.    Elapsed: 0:05:44.\n",
            "  Batch 1,275  of  3,000.    Elapsed: 0:05:51.\n",
            "  Batch 1,300  of  3,000.    Elapsed: 0:05:58.\n",
            "  Batch 1,325  of  3,000.    Elapsed: 0:06:05.\n",
            "  Batch 1,350  of  3,000.    Elapsed: 0:06:12.\n",
            "  Batch 1,375  of  3,000.    Elapsed: 0:06:19.\n",
            "  Batch 1,400  of  3,000.    Elapsed: 0:06:25.\n",
            "  Batch 1,425  of  3,000.    Elapsed: 0:06:32.\n",
            "  Batch 1,450  of  3,000.    Elapsed: 0:06:39.\n",
            "  Batch 1,475  of  3,000.    Elapsed: 0:06:46.\n",
            "  Batch 1,500  of  3,000.    Elapsed: 0:06:53.\n",
            "  Batch 1,525  of  3,000.    Elapsed: 0:07:00.\n",
            "  Batch 1,550  of  3,000.    Elapsed: 0:07:07.\n",
            "  Batch 1,575  of  3,000.    Elapsed: 0:07:14.\n",
            "  Batch 1,600  of  3,000.    Elapsed: 0:07:20.\n",
            "  Batch 1,625  of  3,000.    Elapsed: 0:07:27.\n",
            "  Batch 1,650  of  3,000.    Elapsed: 0:07:34.\n",
            "  Batch 1,675  of  3,000.    Elapsed: 0:07:41.\n",
            "  Batch 1,700  of  3,000.    Elapsed: 0:07:48.\n",
            "  Batch 1,725  of  3,000.    Elapsed: 0:07:55.\n",
            "  Batch 1,750  of  3,000.    Elapsed: 0:08:02.\n",
            "  Batch 1,775  of  3,000.    Elapsed: 0:08:09.\n",
            "  Batch 1,800  of  3,000.    Elapsed: 0:08:16.\n",
            "  Batch 1,825  of  3,000.    Elapsed: 0:08:22.\n",
            "  Batch 1,850  of  3,000.    Elapsed: 0:08:29.\n",
            "  Batch 1,875  of  3,000.    Elapsed: 0:08:36.\n",
            "  Batch 1,900  of  3,000.    Elapsed: 0:08:43.\n",
            "  Batch 1,925  of  3,000.    Elapsed: 0:08:50.\n",
            "  Batch 1,950  of  3,000.    Elapsed: 0:08:57.\n",
            "  Batch 1,975  of  3,000.    Elapsed: 0:09:04.\n",
            "  Batch 2,000  of  3,000.    Elapsed: 0:09:11.\n",
            "  Batch 2,025  of  3,000.    Elapsed: 0:09:18.\n",
            "  Batch 2,050  of  3,000.    Elapsed: 0:09:24.\n",
            "  Batch 2,075  of  3,000.    Elapsed: 0:09:31.\n",
            "  Batch 2,100  of  3,000.    Elapsed: 0:09:38.\n",
            "  Batch 2,125  of  3,000.    Elapsed: 0:09:45.\n",
            "  Batch 2,150  of  3,000.    Elapsed: 0:09:52.\n",
            "  Batch 2,175  of  3,000.    Elapsed: 0:09:59.\n",
            "  Batch 2,200  of  3,000.    Elapsed: 0:10:06.\n",
            "  Batch 2,225  of  3,000.    Elapsed: 0:10:13.\n",
            "  Batch 2,250  of  3,000.    Elapsed: 0:10:19.\n",
            "  Batch 2,275  of  3,000.    Elapsed: 0:10:26.\n",
            "  Batch 2,300  of  3,000.    Elapsed: 0:10:33.\n",
            "  Batch 2,325  of  3,000.    Elapsed: 0:10:40.\n",
            "  Batch 2,350  of  3,000.    Elapsed: 0:10:47.\n",
            "  Batch 2,375  of  3,000.    Elapsed: 0:10:54.\n",
            "  Batch 2,400  of  3,000.    Elapsed: 0:11:01.\n",
            "  Batch 2,425  of  3,000.    Elapsed: 0:11:08.\n",
            "  Batch 2,450  of  3,000.    Elapsed: 0:11:14.\n",
            "  Batch 2,475  of  3,000.    Elapsed: 0:11:21.\n",
            "  Batch 2,500  of  3,000.    Elapsed: 0:11:28.\n",
            "  Batch 2,525  of  3,000.    Elapsed: 0:11:35.\n",
            "  Batch 2,550  of  3,000.    Elapsed: 0:11:42.\n",
            "  Batch 2,575  of  3,000.    Elapsed: 0:11:49.\n",
            "  Batch 2,600  of  3,000.    Elapsed: 0:11:56.\n",
            "  Batch 2,625  of  3,000.    Elapsed: 0:12:03.\n",
            "  Batch 2,650  of  3,000.    Elapsed: 0:12:10.\n",
            "  Batch 2,675  of  3,000.    Elapsed: 0:12:16.\n",
            "  Batch 2,700  of  3,000.    Elapsed: 0:12:23.\n",
            "  Batch 2,725  of  3,000.    Elapsed: 0:12:30.\n",
            "  Batch 2,750  of  3,000.    Elapsed: 0:12:37.\n",
            "  Batch 2,775  of  3,000.    Elapsed: 0:12:44.\n",
            "  Batch 2,800  of  3,000.    Elapsed: 0:12:51.\n",
            "  Batch 2,825  of  3,000.    Elapsed: 0:12:58.\n",
            "  Batch 2,850  of  3,000.    Elapsed: 0:13:05.\n",
            "  Batch 2,875  of  3,000.    Elapsed: 0:13:11.\n",
            "  Batch 2,900  of  3,000.    Elapsed: 0:13:18.\n",
            "  Batch 2,925  of  3,000.    Elapsed: 0:13:25.\n",
            "  Batch 2,950  of  3,000.    Elapsed: 0:13:32.\n",
            "  Batch 2,975  of  3,000.    Elapsed: 0:13:39.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:13:46\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:54:57 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB1GceHZZr84"
      },
      "source": [
        "def print_reviews(sents):\n",
        "  for k, s in enumerate(sents):\n",
        "    print(f\"\\nREVIEW {k}\")\n",
        "    buffer = 0\n",
        "    i = 0\n",
        "    words = s.split()\n",
        "    for j, w in enumerate(words):\n",
        "        buffer += len(w)\n",
        "        if buffer >= 60:\n",
        "          print(' '.join(words[i:j]))\n",
        "          i = j\n",
        "          buffer = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOgfM_8TIJDI",
        "outputId": "96313b50-c69f-4172-c2f5-19c1cfc645b4"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':100,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 40,\n",
        "              # 'top_k': 30,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 1000,\n",
        "             'seed_text': \"[pos-0] [pos-1] [pos-2] \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "print_reviews(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REVIEW 0\n",
            "era un viaggio a 3 stelle e mi auguro che almeno non lo era. le camere sono\n",
            "notevoli, pero per alcune sono della stessa categoria e percio, direi che un 3\n",
            "stelle su 4 non bastano per i mezzi di pensione. nel complesso una buona\n",
            "pensione. camere standard. si dorme al piano pulitissima, assolutamente buio\n",
            "per evitare che c'e gente alla guida della propria macchina. devo dire che\n",
            "e un hotel molto strano come il servizio di lavanderia, non c'e gente ed i\n",
            "tavoli per fare il controllo della doccia sporca sulla strada era grane. la\n",
            "scelta e veramente limitata, la cena e gradevole ( assortita ). cosa successa\n",
            "veramente inquietante sarebbe quella della mensa adiacente, tanto che a me non e\n",
            "stata voglia assolutamente di fare nulla da dire del personale, loro si\n",
            "\n",
            "REVIEW 1\n",
            "non si puo neanche pensare che siate rimasti delusi da questo hotel\n",
            "trovarsi dal lato della stazione della metropolitana a milano allora le camere\n",
            "erano pulite.. la prima colazione e importante da fare una mattina... in\n",
            "estate venezia vi piacerebbe quasi andare fuori, ma tutto il resto e la\n",
            "migliore e migliore, quando un sacco di persone intorno all'isola erano molto\n",
            "piu consapevoli... venezia era e sicuramente un po'meglio degli altri\n",
            "hotel! spero che le recensioni vostre sono state negative!! era tutti i miei\n",
            "colleghi, nessun altro e non solo amici, che stanno andando con i lavori\n",
            "turistici full site!!! ma non solo... molto lunga e portera solo alla rovina!!!\n",
            "sporche che questo e? una lamentela. un risparmio economico aveva bisogno di\n",
            "\n",
            "REVIEW 2\n",
            "hotel. prossima meta di venezia per la spa. servizio fino a fine pasto.\n",
            "la vistosa accoglienza che avevamo trovato solo da uno di un altro\n",
            "cliente sulla carta, ma la nostra bella cena lascia perdere. la spa expo e\n",
            "poi..... tutti questi strati di scuse e fastidi anche sotto il letto e informare\n",
            "dei suoi clienti scortese non sappiamo questo! ”. tutti e alcuni ospiti\n",
            "della spa, tutti saranno probabilmente poco sicuro che questo sia un 5\n",
            "stelle. a questo punto si sapra subito.... sala ristorante ( che non\n",
            "rispecchia il mio nome : come scegliere un 5 stelle per una cena in piscina? ) con\n",
            "porzioni molto ricche rispetto a come vengono cucinati i tavoli... sala spagg\n",
            "CPU times: user 18.5 s, sys: 26.1 ms, total: 18.5 s\n",
            "Wall time: 18.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fg7mXYjJF5n",
        "outputId": "54fc2e09-230e-4688-dbb5-47b028bba029"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':300,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 40,\n",
        "              'top_k': 30,\n",
        "              'generation_method':'parallel',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              # 'burnin': 450,\n",
        "              'max_iter': 1000,\n",
        "             'seed_text': \"[neg-0] [neg-1] [neg-2] \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "print_reviews(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REVIEW 0\n",
            "il duomo e un gioiello di architettura nel centro, la lobby. la non e\n",
            "buona per le altre camere o le porte per entrare in camera dal.. ma per la.....\n",
            "esperienza una bocciatura. terribile... in italia la colazione e buona non di\n",
            "tutto il resto andateci. non andateci abbiamo sicuramente provato la \"\n",
            "colazione con i dolci \" camera da letto negli hotel periferici di questa citta...\n",
            "la risposta e no non ci mettera piede.. \" solo \".. \" solo \" le persone che\n",
            "cura per la colazione e non l'italiano.. solo \"? o \" solo \" era la cameriera\n",
            "che mi ha preceduto con il \" suo \" solo \"? ho risposto \" solo \" mi ha risposto\n",
            "solo il... e'sicuro, manca l'accesso di vicini e wi - fi e.... in realta\n",
            "chiedere se si spegne. le camere forniscono collegamenti con la camera tramite\n",
            "la quale non avevo letto la prima ricerca..... camere charmese e\n",
            "confortevoli con mo e bagno sporchi. il letto / wc sembrava un pole stile paradisia\n",
            "che soggiornariati come servizi e altri servizi. la colazione a\n",
            "sopportare l'usura, tutti i tipi doccia, camera, tutte le tende nelle camere non,\n",
            "i servizi nelle camere, la maggior delle camere non, i bagni nelle\n",
            "camere e tutte le stanze sporse con tutte le docce dei bambini, tutto il segno\n",
            "dentale che ci hanno fatto per tutta la cosa. tutte le lenzuola del letto, i\n",
            "rubinetti del riscaldamento, i vecchi bagni, i vassoi nella camera degli\n",
            "\n",
            "REVIEW 1\n",
            ".... servizio stalti da li............ pulizia da li... lsdo....\n",
            "pulizia...... camere sporche e sporche.... sconsigliatissimo...... anche la\n",
            "pulizia e da li......... sopra la prima foto vecchia delle camere ha la\n",
            "tapparella e talmente sporca e neppure la minima pulizia.. la piscina davvero \"\n",
            "pulita \" e e ', la sauna e impossibile...... vergogna!. abbiamo appuntamento\n",
            "con i suoi amici.. anche una cena era possibile.. la cucina e grande...\n",
            "ma..... la mancanza di tranquillita il resto.......... per cui e sufficiente\n",
            "prenotare una \" spa \"... e la donna disse quale sarebbe successa causa... \" ls\n",
            "confido.. \". carino il dell'accoglienza... brutta la sorpresa.. la chiave....\n",
            "il parcheggio... la rack - room erano pulite.... la camera da letto...\n",
            "non c'e stato il trattamento 5 stelle \"....... troppo poco per un cornetto\n",
            "+ un da pagare...... trattandosi di una struttura che e una pensione,\n",
            "non e sufficiente per ottenere un servizio di qualita superiore ma\n",
            "bisogna arrivare alla reception. tutto a posto ( cordialmente, loc. per le\n",
            "\n",
            "REVIEW 2\n",
            "....... ascensore principale con bagno in legno.. personale\n",
            "irrispettoso.......... pulizia camere per disabili......... staff scortese quasi\n",
            "completo... pulite camere dozzinali...... lenzuola macchiate biancheria\n",
            "bucata.... personale assente, scortese... non solo : personale fastidioso...\n",
            "l'assurdo. le critiche disparate da parte personale.... le\n",
            "pulizie............ pulizia camere ricoperte spazio... tutto.......... ascensore di\n",
            "servizio......... le camere sono rozze obsolete. pulizia camere bucate senza bagno\n",
            "interno... gestione inappropriata del personale.. lavoro scortese da\n",
            "dimenticare. in un hotel diverso ero con la signora che c'era....... con....\n",
            "personale scortese ed invaso., personale molto scortese... personale\n",
            "invadente il letto e alto e minusco..... sembra un muro. pulizia........ staff\n",
            "assentee.. non cordiale. pulizia cameretti e personale assente............\n",
            "quello che la ragazza definisce \" pulizia camere... \". servizio non e proprio\n",
            "il tipo di servizio che c'e.. pesco. pulizia\n",
            "CPU times: user 46.2 s, sys: 68 ms, total: 46.2 s\n",
            "Wall time: 46.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNR2y4dHJP-z",
        "outputId": "bdbb8a82-fe27-42e6-b0b2-acf2a22903fa"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':200,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 30,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              'burnin': 900,\n",
        "              'max_iter': 1000,\n",
        "             'seed_text': \"[pos-0] [pos-1] [pos-2] \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "print_reviews(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REVIEW 0\n",
            "assolutamente molto deludente, con tutte le strutture una corsa,\n",
            "senza raggiungere il porto. benche si sia rivelato molto invidiabile, il\n",
            "prezzo e statodito. non capisco come sia lo spazio. da tralasciare la stanza\n",
            "non super elegante, il bagno parole di lode. la colazione veramente\n",
            "mediocre per la qualita degli. solo le 4 fette del piano cottura erano di pando e\n",
            "di porchetta, invece anche le sfogliatelle per la pizza, ma con tutte\n",
            "leta buone in piu la varieta di antipasti ma anche le mazzacene. le\n",
            "cameriere fanno uso di un. il della colazione era, quasi scortese. si quando si\n",
            "stendevano di quellene che di gamberi duri. piatti lunghi buffet freddi con una\n",
            "piazzola di insalata dicciata per il resto si per scontatova latta che si erato\n",
            "con un osso duro. non ci sono un posto, certo per il mare per spiaggia, per la\n",
            "spiaggia. nota positiva la cena in spiaggia e il peggior di di un albergo. penso\n",
            "\n",
            "REVIEW 1\n",
            "dire che la grande cosa sia da parti, ma la mia cara recensione non male\n",
            "mi sono abbastanza per tutte quelle cose. il b & e un perfetto, c'e un\n",
            "autobus ogni 10 minuti e si trova in un posto molto bello, si sente molto\n",
            "superlative, e quindi tratta di una vera truffa tutta la questione, tutto va bene per\n",
            "qualche motivo quindi si dimostra che non ci e un problema : - ) il cameriere\n",
            "lavora al tavolo, a colazione sul suo tavolo il personale della e, il che\n",
            "abbiamo dovuto pagare piu perche non c'era un paio di stanze disponibili, e il\n",
            "wifi non disponibile, le delle camere si salva tanto il il era buono, questo\n",
            "albergo 4 stelle merita un, e soluzione migliore per evitare lata di\n",
            "considerando che la differenza di prezzo e il tutto, ma questo e un caro. ho molto male\n",
            "e mi auguro una volta a prenotare una copia di una la volta ci, non voglio\n",
            "\n",
            "REVIEW 2\n",
            "oh, un hotel che vuole dire questo, non c'e che dire, c'e la di riarsene\n",
            "senza dover essere informati ma alcuni dei nostri clienti mi, certo, non\n",
            "abbiamo visto il e abbiamo il ristorante, ma, caso, non c'era, e dire che,\n",
            "certo, non mi andava, ma presente, la mia infartizzazione, che e una\n",
            "tristezza, che c'e di fatto, ma questo perche, per il diverso, pensavo fosse lo\n",
            "stesso che non mai, ma le erano tutte diverse molti aspetti, la del, pero, e, se\n",
            "troppo nei dettagli, un hotel, questo e un punto di, ma la,, volta e carina, che\n",
            "dire no, ma questo non e davvero per il fatto che in molte occasioni decido di\n",
            "visitare un posto cosi, non si puo delu, il minimo certo, con il della, i letti\n",
            "CPU times: user 28.4 s, sys: 24 ms, total: 28.4 s\n",
            "Wall time: 28.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSLKdyHDYSdD",
        "outputId": "7ebdfcea-8edb-45dc-83c8-1a5cd1b7b11c"
      },
      "source": [
        "%%time\n",
        "parameters = {'n_sentences': 3,  \n",
        "              'batch_size': 3,\n",
        "              'avg_len':200,\n",
        "              'max_len':1000,\n",
        "              'std_len' : 30,\n",
        "              'top_k': 100,\n",
        "              'generation_method':'attention',\n",
        "              'temperature': 1,\n",
        "              'sample': True,\n",
        "              'burnin': 900,\n",
        "              'max_iter': 1000,\n",
        "             'seed_text': \"[neg-0] [neg-1] [neg-2] \",\n",
        "              }\n",
        "\n",
        "\n",
        "sents = it_bert_model.generate(save_to_path='/content/prova.txt', **parameters)\n",
        "\n",
        "print_reviews(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REVIEW 0\n",
            "per due volte meritava cinque stelle con solo poche bevande\n",
            "chilometriche. tutto questo solo per il buon prezzo rispetto ad una struttura a 5....\n",
            "questo hotel e davvero molto.. peccato che sono rimasta molto delusa, ho\n",
            "dovuto una camera matrimoniale e ne avevo una doppia se non una sola e non era\n",
            "presente nemmeno una struttura ad.... nel complesso tutto questo a\n",
            "anche...... non si trova qualcuno che possa controllare il posizionamento del\n",
            "letto o quello del letto.... senza. e stato veramente impossibile trovare\n",
            "un hotel a 5 stelle... la mia esperienza deve essere trasformata piu un\n",
            "hotel... e..... anche se si puo dire che in realta e un hotel a.... che dire.. non\n",
            "\n",
            "REVIEW 1\n",
            "soggiornato per un grand tour internazionale e, ripeto, altro\n",
            "ancora. mi sembra essere molto soddisfatto della situazione. il grand hotel e\n",
            "bellissimo, pulito e arredamento molto e un servizio adeguato........ e stato un\n",
            "buon auspicio tutto quello che si e verificato con........... i canali\n",
            "comunicanti del teatro, o semplicemente per le rappresentazioni, non hanno\n",
            "ricevuto alcuna risposta.... un po............ il atteggiamento da\n",
            "receptionist di............... niente da dire, addetti alla reception parlano da\n",
            "\n",
            "REVIEW 2\n",
            "prezzo della camera.., veramente sca.. e solo per l'assenza dito..\n",
            "location poco curata.. in questo caso un hotel che sembra essere un\n",
            "sottoscala... di positivo c'e, soprattutto per quanto riguarda il cortile\n",
            "interno,tte e molte macchie evidenti... che fanno un 4 stelle di standard... un\n",
            "buon primo piano idem non la colazione, area varia discreta... ma non in\n",
            "alla qualita della stanza.. buona la cortesia dello staff usata come luogo\n",
            "di ritrovo.... e per il resto tutto resto passa di sola volonta per la\n",
            "qualita il resto procede al giusto..... camera da evitare... la posto non e\n",
            "CPU times: user 21.9 s, sys: 47 ms, total: 22 s\n",
            "Wall time: 22 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ztlLDoANYTXK",
        "outputId": "20d6d0d7-4b0c-4e16-f9eb-78bbc87ba6e5"
      },
      "source": [
        "' '.join(s.split()[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nn lo so non non accendo se veramente e necessario...'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn-JFPN5YcZO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}